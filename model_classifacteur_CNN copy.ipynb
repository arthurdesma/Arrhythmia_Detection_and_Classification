{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fusionné = pd.read_csv('df_fusionné.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fusionné_binaire = df_fusionné.sample(frac=0.01)\n",
    "df_fusionné_binaire.iloc[:, 0] = df_fusionné_binaire.iloc[:, 0].apply(lambda x: 0 if x == 'N' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = df_fusionné_binaire.iloc[:, 0].value_counts()\n",
    "min_count = counts.min()\n",
    "\n",
    "# Create balanced DataFrame through undersampling\n",
    "df_balanced_under = pd.concat([\n",
    "    df_fusionné_binaire[df_fusionné_binaire.iloc[:, 0] == 0].sample(min_count),\n",
    "    df_fusionné_binaire[df_fusionné_binaire.iloc[:, 0] == 1].sample(min_count)\n",
    "])\n",
    "\n",
    "# Shuffle the DataFrame to mix the classes\n",
    "df_balanced_under = df_balanced_under.sample(frac=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ColumnName\n",
      "0    328\n",
      "1    328\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "value_counts = df_balanced_under.iloc[:, 0].value_counts()\n",
    "\n",
    "print(value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ColumnName</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>350</th>\n",
       "      <th>351</th>\n",
       "      <th>352</th>\n",
       "      <th>353</th>\n",
       "      <th>354</th>\n",
       "      <th>355</th>\n",
       "      <th>356</th>\n",
       "      <th>357</th>\n",
       "      <th>358</th>\n",
       "      <th>359</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>215877</th>\n",
       "      <td>0</td>\n",
       "      <td>0.513085</td>\n",
       "      <td>0.510930</td>\n",
       "      <td>0.508412</td>\n",
       "      <td>0.505665</td>\n",
       "      <td>0.506288</td>\n",
       "      <td>0.507966</td>\n",
       "      <td>0.509988</td>\n",
       "      <td>0.512084</td>\n",
       "      <td>0.512323</td>\n",
       "      <td>...</td>\n",
       "      <td>0.565390</td>\n",
       "      <td>0.560164</td>\n",
       "      <td>0.547038</td>\n",
       "      <td>0.531940</td>\n",
       "      <td>0.512004</td>\n",
       "      <td>0.492814</td>\n",
       "      <td>0.491098</td>\n",
       "      <td>0.495708</td>\n",
       "      <td>0.503470</td>\n",
       "      <td>0.512605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164905</th>\n",
       "      <td>1</td>\n",
       "      <td>0.517769</td>\n",
       "      <td>0.517934</td>\n",
       "      <td>0.518108</td>\n",
       "      <td>0.518293</td>\n",
       "      <td>0.518484</td>\n",
       "      <td>0.518674</td>\n",
       "      <td>0.518873</td>\n",
       "      <td>0.519062</td>\n",
       "      <td>0.519202</td>\n",
       "      <td>...</td>\n",
       "      <td>0.517529</td>\n",
       "      <td>0.517415</td>\n",
       "      <td>0.517371</td>\n",
       "      <td>0.517364</td>\n",
       "      <td>0.517388</td>\n",
       "      <td>0.517435</td>\n",
       "      <td>0.517468</td>\n",
       "      <td>0.517512</td>\n",
       "      <td>0.517565</td>\n",
       "      <td>0.517635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17801</th>\n",
       "      <td>1</td>\n",
       "      <td>0.508990</td>\n",
       "      <td>0.507537</td>\n",
       "      <td>0.505771</td>\n",
       "      <td>0.504139</td>\n",
       "      <td>0.503860</td>\n",
       "      <td>0.504044</td>\n",
       "      <td>0.505291</td>\n",
       "      <td>0.506918</td>\n",
       "      <td>0.506187</td>\n",
       "      <td>...</td>\n",
       "      <td>0.514587</td>\n",
       "      <td>0.514150</td>\n",
       "      <td>0.513626</td>\n",
       "      <td>0.513063</td>\n",
       "      <td>0.512324</td>\n",
       "      <td>0.511562</td>\n",
       "      <td>0.511087</td>\n",
       "      <td>0.510623</td>\n",
       "      <td>0.510439</td>\n",
       "      <td>0.510208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49367</th>\n",
       "      <td>0</td>\n",
       "      <td>0.432822</td>\n",
       "      <td>0.432580</td>\n",
       "      <td>0.432382</td>\n",
       "      <td>0.432204</td>\n",
       "      <td>0.431972</td>\n",
       "      <td>0.431753</td>\n",
       "      <td>0.431532</td>\n",
       "      <td>0.431353</td>\n",
       "      <td>0.431376</td>\n",
       "      <td>...</td>\n",
       "      <td>0.435205</td>\n",
       "      <td>0.435287</td>\n",
       "      <td>0.435123</td>\n",
       "      <td>0.434859</td>\n",
       "      <td>0.434563</td>\n",
       "      <td>0.434235</td>\n",
       "      <td>0.433945</td>\n",
       "      <td>0.433666</td>\n",
       "      <td>0.433369</td>\n",
       "      <td>0.433079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174335</th>\n",
       "      <td>0</td>\n",
       "      <td>0.467863</td>\n",
       "      <td>0.469652</td>\n",
       "      <td>0.471438</td>\n",
       "      <td>0.473166</td>\n",
       "      <td>0.474737</td>\n",
       "      <td>0.476081</td>\n",
       "      <td>0.476056</td>\n",
       "      <td>0.475514</td>\n",
       "      <td>0.475564</td>\n",
       "      <td>...</td>\n",
       "      <td>0.467835</td>\n",
       "      <td>0.467647</td>\n",
       "      <td>0.467626</td>\n",
       "      <td>0.467647</td>\n",
       "      <td>0.467963</td>\n",
       "      <td>0.468316</td>\n",
       "      <td>0.468051</td>\n",
       "      <td>0.467739</td>\n",
       "      <td>0.467141</td>\n",
       "      <td>0.466682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120395</th>\n",
       "      <td>1</td>\n",
       "      <td>0.509849</td>\n",
       "      <td>0.509024</td>\n",
       "      <td>0.508791</td>\n",
       "      <td>0.509198</td>\n",
       "      <td>0.508420</td>\n",
       "      <td>0.507397</td>\n",
       "      <td>0.506716</td>\n",
       "      <td>0.506124</td>\n",
       "      <td>0.505558</td>\n",
       "      <td>...</td>\n",
       "      <td>0.539114</td>\n",
       "      <td>0.538541</td>\n",
       "      <td>0.539547</td>\n",
       "      <td>0.540360</td>\n",
       "      <td>0.542500</td>\n",
       "      <td>0.543953</td>\n",
       "      <td>0.538698</td>\n",
       "      <td>0.531260</td>\n",
       "      <td>0.522166</td>\n",
       "      <td>0.512971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189909</th>\n",
       "      <td>1</td>\n",
       "      <td>0.472411</td>\n",
       "      <td>0.472263</td>\n",
       "      <td>0.471358</td>\n",
       "      <td>0.469383</td>\n",
       "      <td>0.467435</td>\n",
       "      <td>0.465418</td>\n",
       "      <td>0.462476</td>\n",
       "      <td>0.459567</td>\n",
       "      <td>0.458954</td>\n",
       "      <td>...</td>\n",
       "      <td>0.416110</td>\n",
       "      <td>0.410512</td>\n",
       "      <td>0.412699</td>\n",
       "      <td>0.418475</td>\n",
       "      <td>0.424608</td>\n",
       "      <td>0.431960</td>\n",
       "      <td>0.440728</td>\n",
       "      <td>0.449577</td>\n",
       "      <td>0.459913</td>\n",
       "      <td>0.469578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10684</th>\n",
       "      <td>1</td>\n",
       "      <td>0.482363</td>\n",
       "      <td>0.481423</td>\n",
       "      <td>0.480602</td>\n",
       "      <td>0.479819</td>\n",
       "      <td>0.478890</td>\n",
       "      <td>0.478017</td>\n",
       "      <td>0.477116</td>\n",
       "      <td>0.476362</td>\n",
       "      <td>0.476322</td>\n",
       "      <td>...</td>\n",
       "      <td>0.490187</td>\n",
       "      <td>0.489811</td>\n",
       "      <td>0.489148</td>\n",
       "      <td>0.488356</td>\n",
       "      <td>0.487485</td>\n",
       "      <td>0.486564</td>\n",
       "      <td>0.485734</td>\n",
       "      <td>0.484916</td>\n",
       "      <td>0.484094</td>\n",
       "      <td>0.483273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38718</th>\n",
       "      <td>0</td>\n",
       "      <td>0.487630</td>\n",
       "      <td>0.489171</td>\n",
       "      <td>0.490645</td>\n",
       "      <td>0.492164</td>\n",
       "      <td>0.493904</td>\n",
       "      <td>0.495619</td>\n",
       "      <td>0.497444</td>\n",
       "      <td>0.499124</td>\n",
       "      <td>0.499870</td>\n",
       "      <td>...</td>\n",
       "      <td>0.479950</td>\n",
       "      <td>0.480111</td>\n",
       "      <td>0.480622</td>\n",
       "      <td>0.481298</td>\n",
       "      <td>0.482141</td>\n",
       "      <td>0.483077</td>\n",
       "      <td>0.483843</td>\n",
       "      <td>0.484631</td>\n",
       "      <td>0.485426</td>\n",
       "      <td>0.486302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135223</th>\n",
       "      <td>0</td>\n",
       "      <td>0.503047</td>\n",
       "      <td>0.504010</td>\n",
       "      <td>0.504658</td>\n",
       "      <td>0.504997</td>\n",
       "      <td>0.505830</td>\n",
       "      <td>0.506726</td>\n",
       "      <td>0.507463</td>\n",
       "      <td>0.508115</td>\n",
       "      <td>0.508586</td>\n",
       "      <td>...</td>\n",
       "      <td>0.473221</td>\n",
       "      <td>0.483971</td>\n",
       "      <td>0.486322</td>\n",
       "      <td>0.486212</td>\n",
       "      <td>0.485754</td>\n",
       "      <td>0.485142</td>\n",
       "      <td>0.488109</td>\n",
       "      <td>0.492145</td>\n",
       "      <td>0.496633</td>\n",
       "      <td>0.501100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>656 rows × 361 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ColumnName         0         1         2         3         4         5  \\\n",
       "215877          0  0.513085  0.510930  0.508412  0.505665  0.506288  0.507966   \n",
       "164905          1  0.517769  0.517934  0.518108  0.518293  0.518484  0.518674   \n",
       "17801           1  0.508990  0.507537  0.505771  0.504139  0.503860  0.504044   \n",
       "49367           0  0.432822  0.432580  0.432382  0.432204  0.431972  0.431753   \n",
       "174335          0  0.467863  0.469652  0.471438  0.473166  0.474737  0.476081   \n",
       "...           ...       ...       ...       ...       ...       ...       ...   \n",
       "120395          1  0.509849  0.509024  0.508791  0.509198  0.508420  0.507397   \n",
       "189909          1  0.472411  0.472263  0.471358  0.469383  0.467435  0.465418   \n",
       "10684           1  0.482363  0.481423  0.480602  0.479819  0.478890  0.478017   \n",
       "38718           0  0.487630  0.489171  0.490645  0.492164  0.493904  0.495619   \n",
       "135223          0  0.503047  0.504010  0.504658  0.504997  0.505830  0.506726   \n",
       "\n",
       "               6         7         8  ...       350       351       352  \\\n",
       "215877  0.509988  0.512084  0.512323  ...  0.565390  0.560164  0.547038   \n",
       "164905  0.518873  0.519062  0.519202  ...  0.517529  0.517415  0.517371   \n",
       "17801   0.505291  0.506918  0.506187  ...  0.514587  0.514150  0.513626   \n",
       "49367   0.431532  0.431353  0.431376  ...  0.435205  0.435287  0.435123   \n",
       "174335  0.476056  0.475514  0.475564  ...  0.467835  0.467647  0.467626   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "120395  0.506716  0.506124  0.505558  ...  0.539114  0.538541  0.539547   \n",
       "189909  0.462476  0.459567  0.458954  ...  0.416110  0.410512  0.412699   \n",
       "10684   0.477116  0.476362  0.476322  ...  0.490187  0.489811  0.489148   \n",
       "38718   0.497444  0.499124  0.499870  ...  0.479950  0.480111  0.480622   \n",
       "135223  0.507463  0.508115  0.508586  ...  0.473221  0.483971  0.486322   \n",
       "\n",
       "             353       354       355       356       357       358       359  \n",
       "215877  0.531940  0.512004  0.492814  0.491098  0.495708  0.503470  0.512605  \n",
       "164905  0.517364  0.517388  0.517435  0.517468  0.517512  0.517565  0.517635  \n",
       "17801   0.513063  0.512324  0.511562  0.511087  0.510623  0.510439  0.510208  \n",
       "49367   0.434859  0.434563  0.434235  0.433945  0.433666  0.433369  0.433079  \n",
       "174335  0.467647  0.467963  0.468316  0.468051  0.467739  0.467141  0.466682  \n",
       "...          ...       ...       ...       ...       ...       ...       ...  \n",
       "120395  0.540360  0.542500  0.543953  0.538698  0.531260  0.522166  0.512971  \n",
       "189909  0.418475  0.424608  0.431960  0.440728  0.449577  0.459913  0.469578  \n",
       "10684   0.488356  0.487485  0.486564  0.485734  0.484916  0.484094  0.483273  \n",
       "38718   0.481298  0.482141  0.483077  0.483843  0.484631  0.485426  0.486302  \n",
       "135223  0.486212  0.485754  0.485142  0.488109  0.492145  0.496633  0.501100  \n",
       "\n",
       "[656 rows x 361 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced_under"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_balanced_under.iloc[:, 1:]  \n",
    "y = df_balanced_under.iloc[:, 0] \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_train.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.astype(int)\n",
    "y_test = y_test.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arthurdesmazures/venv-metal/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, BatchNormalization, MaxPooling1D, Dropout, Flatten, Dense\n",
    "from keras.optimizers import Adam, Adadelta\n",
    "\n",
    "Model = Sequential()\n",
    "\n",
    "Model.add(Conv1D(512, 20, strides=1, padding=\"same\", activation=\"relu\", input_shape=(360, 1)))\n",
    "Model.add(BatchNormalization())\n",
    "Model.add(MaxPooling1D(3, strides=2, padding=\"same\"))\n",
    "\n",
    "Model.add(Conv1D(256, 20, strides=1, padding=\"same\", activation=\"relu\"))\n",
    "Model.add(Dropout(0.2))\n",
    "Model.add(MaxPooling1D(3, strides=2, padding=\"same\"))\n",
    "\n",
    "Model.add(Conv1D(1024, 20, strides=1, padding=\"same\", activation=\"relu\"))\n",
    "Model.add(Dropout(0.2))\n",
    "Model.add(MaxPooling1D(3, strides=2, padding=\"same\"))\n",
    "\n",
    "Model.add(Conv1D(128, 20, strides=1, padding=\"same\", activation=\"relu\"))\n",
    "Model.add(Dropout(0.2))\n",
    "Model.add(MaxPooling1D(3, strides=2, padding=\"same\"))\n",
    "\n",
    "Model.add(Conv1D(256, 20, strides=1, padding=\"same\", activation=\"relu\"))\n",
    "Model.add(Dropout(0.2))\n",
    "Model.add(MaxPooling1D(3, strides=2, padding=\"same\"))\n",
    "\n",
    "Model.add(Conv1D(64, 20, strides=1, padding=\"same\", activation=\"relu\"))\n",
    "Model.add(Dropout(0.2))\n",
    "Model.add(MaxPooling1D(3, strides=2, padding=\"same\"))\n",
    "\n",
    "Model.add(Conv1D(32, 20, strides=1, padding=\"same\", activation=\"relu\"))\n",
    "Model.add(Dropout(0.2))\n",
    "Model.add(MaxPooling1D(3, strides=2, padding=\"same\"))\n",
    "\n",
    "Model.add(Flatten())\n",
    "Model.add(Dense(1024, activation='relu'))\n",
    "Model.add(Dropout(0.2))\n",
    "\n",
    "Model.add(Dense(512, activation='relu'))\n",
    "Model.add(Dropout(0.2))\n",
    "\n",
    "Model.add(Dense(64, activation='relu'))\n",
    "Model.add(Dropout(0.2))\n",
    "\n",
    "Model.add(Dense(units=1, activation='sigmoid'))  # Use 'sigmoid' for binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.keras.wrappers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Adam\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EarlyStopping\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwrappers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mscikit_learn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KerasClassifier\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Define a function to create the Keras model with variable parameters\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_model\u001b[39m(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.keras.wrappers'"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "# Define a function to create the Keras model with variable parameters\n",
    "def create_model(optimizer='adam'):\n",
    "    Model = Sequential()\n",
    "\n",
    "    Model.add(Conv1D(512, 20, strides=1, padding=\"same\", activation=\"relu\", input_shape=(360, 1)))\n",
    "    Model.add(BatchNormalization())\n",
    "    Model.add(MaxPooling1D(3, strides=2, padding=\"same\"))\n",
    "\n",
    "    Model.add(Conv1D(256, 20, strides=1, padding=\"same\", activation=\"relu\"))\n",
    "    Model.add(Dropout(0.2))\n",
    "    Model.add(MaxPooling1D(3, strides=2, padding=\"same\"))\n",
    "\n",
    "    Model.add(Conv1D(1024, 20, strides=1, padding=\"same\", activation=\"relu\"))\n",
    "    Model.add(Dropout(0.2))\n",
    "    Model.add(MaxPooling1D(3, strides=2, padding=\"same\"))\n",
    "\n",
    "    Model.add(Conv1D(128, 20, strides=1, padding=\"same\", activation=\"relu\"))\n",
    "    Model.add(Dropout(0.2))\n",
    "    Model.add(MaxPooling1D(3, strides=2, padding=\"same\"))\n",
    "\n",
    "    Model.add(Conv1D(256, 20, strides=1, padding=\"same\", activation=\"relu\"))\n",
    "    Model.add(Dropout(0.2))\n",
    "    Model.add(MaxPooling1D(3, strides=2, padding=\"same\"))\n",
    "\n",
    "    Model.add(Conv1D(64, 20, strides=1, padding=\"same\", activation=\"relu\"))\n",
    "    Model.add(Dropout(0.2))\n",
    "    Model.add(MaxPooling1D(3, strides=2, padding=\"same\"))\n",
    "\n",
    "    Model.add(Conv1D(32, 20, strides=1, padding=\"same\", activation=\"relu\"))\n",
    "    Model.add(Dropout(0.2))\n",
    "    Model.add(MaxPooling1D(3, strides=2, padding=\"same\"))\n",
    "\n",
    "    Model.add(Flatten())\n",
    "    Model.add(Dense(1024, activation='relu'))\n",
    "    Model.add(Dropout(0.2))\n",
    "\n",
    "    Model.add(Dense(512, activation='relu'))\n",
    "    Model.add(Dropout(0.2))\n",
    "\n",
    "    Model.add(Dense(64, activation='relu'))\n",
    "    Model.add(Dropout(0.2))\n",
    "\n",
    "    Model.add(Dense(units=1, activation='sigmoid'))  # Use 'sigmoid' for binary classification\n",
    "    return model\n",
    "\n",
    "# Wrap the model using KerasClassifier\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "\n",
    "# Define the grid search parameters\n",
    "param_grid = {\n",
    "    'batch_size': [10, 20, 40],\n",
    "    'epochs': [20, 50, 70],\n",
    "    'optimizer': ['Adam', 'RMSprop']\n",
    "}\n",
    "\n",
    "# Create a callback\n",
    "early_stopper = EarlyStopping(monitor=\"loss\", patience=3, mode=\"min\")\n",
    "\n",
    "# Create GridSearchCV\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_train, y_train, validation_data=(X_test, y_test), callbacks=[early_stopper])\n",
    "\n",
    "# Summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-metal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
