{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1C3t5jw8yhhmhJhmAmzigpomC5UaLXTQm","authorship_tag":"ABX9TyMT26A+fbJ130VgNQ3MW654"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","\n","# Montez votre Google Drive\n","drive.mount('/content/drive')\n","\n","# Accédez au répertoire ProjetE4\n","%cd /content/drive/Othercomputers/Mon\\ ordinateur\\ portable/Documents/GitHub/ProjetE4\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hYI7PNgK7WpV","executionInfo":{"status":"ok","timestamp":1709461907428,"user_tz":-60,"elapsed":35936,"user":{"displayName":"Paul GILQUIN","userId":"17627275338727361666"}},"outputId":"d4759eb1-3dfd-4308-8392-5860dea49f30"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/Othercomputers/Mon ordinateur portable/Documents/GitHub/ProjetE4\n"]}]},{"cell_type":"code","source":["!pip install wfdb\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W1hxv6z47s6O","executionInfo":{"status":"ok","timestamp":1709461914388,"user_tz":-60,"elapsed":6963,"user":{"displayName":"Paul GILQUIN","userId":"17627275338727361666"}},"outputId":"ee2a9a0a-6f6b-4df1-a5b4-ba4e7ab7f2e4"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting wfdb\n","  Downloading wfdb-4.1.2-py3-none-any.whl (159 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/160.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m153.6/160.0 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.0/160.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: SoundFile>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from wfdb) (0.12.1)\n","Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from wfdb) (3.7.1)\n","Requirement already satisfied: numpy>=1.10.1 in /usr/local/lib/python3.10/dist-packages (from wfdb) (1.25.2)\n","Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from wfdb) (1.5.3)\n","Requirement already satisfied: requests>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from wfdb) (2.31.0)\n","Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wfdb) (1.11.4)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->wfdb) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->wfdb) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->wfdb) (4.49.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->wfdb) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->wfdb) (23.2)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->wfdb) (9.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->wfdb) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->wfdb) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.0->wfdb) (2023.4)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.8.1->wfdb) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.8.1->wfdb) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.8.1->wfdb) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.8.1->wfdb) (2024.2.2)\n","Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from SoundFile>=0.10.0->wfdb) (1.16.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->SoundFile>=0.10.0->wfdb) (2.21)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.2.2->wfdb) (1.16.0)\n","Installing collected packages: wfdb\n","Successfully installed wfdb-4.1.2\n"]}]},{"cell_type":"code","source":["# Importation des modules nécessaires\n","import wfdb  # Pour la manipulation de données ECG\n","import csv  # Pour la manipulation de fichiers CSV\n","import pandas as pd  # Pour la manipulation de données tabulaires\n","import numpy as np  # Pour la manipulation de tableaux\n","import os  # Pour les opérations liées au système d'exploitation\n","\n","# Création du répertoire de sortie s'il n'existe pas déjà\n","output_dir = \"data_creation\"\n","os.makedirs(output_dir, exist_ok=True)\n","\n","# Numéros des patients\n","patient_numbers = [\n","    \"100\", \"101\", \"102\", \"103\", \"104\", \"105\", \"106\", \"107\", \"108\", \"109\",\n","    \"111\", \"112\", \"113\", \"114\", \"115\", \"116\", \"117\", \"118\", \"119\", \"121\",\n","    \"122\", \"123\", \"124\", \"200\", \"201\", \"202\", \"203\", \"205\", \"207\", \"208\",\n","    \"209\", \"210\", \"212\", \"213\", \"214\", \"215\", \"217\", \"219\", \"220\", \"221\",\n","    \"222\", \"223\", \"228\", \"230\", \"231\", \"232\", \"233\", \"234\"\n","]\n","\n","\n","# N = normal\n","# S = supra-ventricular premature\n","# V = ventricular escape\n","# F = fusion of ventricular and normal\n","# Q = unclassified heartbeats\n","\n","# Correspondance des symboles aux catégories de battements cardiaques\n","symbol_to_category = {\n","    'N': 'N', '.': 'N', 'L': 'N', 'R': 'N', 'e': 'N', 'j': 'N',\n","    'a': 'S', 'A': 'S', 'J': 'S', 'S': 'S',\n","    'V': 'V', 'E': 'V',\n","    'F': 'F',\n","    '/': 'Q', 'f': 'Q', 'Q': 'Q'\n","}\n","\n","# Parcours de chaque numéro de patient\n","for patient_number in patient_numbers:\n","    try:\n","        # Données ECG\n","        path_to_record = f\"mit-database/{patient_number}\"\n","        patient_record = wfdb.rdrecord(path_to_record)\n","        leads = patient_record.sig_name  # Noms des dérivations ECG\n","        ecg_data = patient_record.p_signal  # Données ECG\n","\n","        # Fichier CSV des données ECG\n","        ecg_filename = f\"{output_dir}/{patient_number}_ECG.csv\"\n","        with open(ecg_filename, \"w\", newline='') as outfile:\n","            out_csv = csv.writer(outfile)\n","            out_csv.writerow(leads)  # Écriture des noms des dérivations\n","            for row in ecg_data:\n","                out_csv.writerow(row)  # Écriture des données ECG\n","\n","        # Données des annotations\n","        annotation = wfdb.rdann(path_to_record, 'atr')\n","        symbols = annotation.symbol  # Symboles des annotations\n","        annotations = annotation.sample  # Échantillons correspondants\n","\n","        # Filtrer les symboles qui ne sont pas dans symbol_to_category\n","        filtered_symbols_annotations = [(sym, ann) for sym, ann in zip(symbols, annotations) if sym in symbol_to_category]\n","        categories = [symbol_to_category[sym] for sym, ann in filtered_symbols_annotations]  # Catégories correspondantes\n","        annotations_filtered = [ann for sym, ann in filtered_symbols_annotations]  # Annotations filtrées\n","\n","        # Création d'un DataFrame pandas pour les annotations\n","        df_annotations = pd.DataFrame({'Category': categories, 'Annotation': annotations_filtered})\n","\n","        # Fichier CSV des annotations\n","        annotations_filename = f\"{output_dir}/{patient_number}_Annotations.csv\"\n","        df_annotations.to_csv(annotations_filename, index=False)  # Écriture des annotations dans le fichier CSV\n","\n","    except Exception as e:\n","        print(f\"Échec de traitement : {patient_number}: {e}\")\n","\n","print(\"Terminé\")\n","\n","# Fonction pour traiter les données d'un patient\n","def process_patient_data(patient_number, data_creation_dir=\"data_creation\"):\n","    ecg_file_path = os.path.join(data_creation_dir, f\"{patient_number}_ECG.csv\")\n","    annotations_file_path = os.path.join(data_creation_dir, f\"{patient_number}_Annotations.csv\")\n","\n","    patient_X = []  # Liste pour stocker les données ECG\n","    patient_Y = []  # Liste pour stocker les catégories correspondantes\n","\n","    try:\n","        ecg_df = pd.read_csv(ecg_file_path)\n","        annotations_df = pd.read_csv(annotations_file_path)\n","    except FileNotFoundError:\n","        print(f\"Fichiers pour le patient {patient_number} non trouvés. Passage au suivant...\")\n","        return [], []\n","\n","    first_column_name = ecg_df.columns[0]  # Nom de la première colonne (nom de la dérivation)\n","\n","    sampling_rate = 360  # Fréquence d'échantillonnage en Hz\n","    window_size_seconds = 3  # Nombre de secondes avant et après l'annotation\n","    window_size_samples = window_size_seconds * sampling_rate  # Nombre d'échantillons dans la fenêtre\n","\n","    for _, row in annotations_df.iterrows():\n","        annotation_point = row['Annotation']  # Point d'annotation\n","        category = row['Category']  # Catégorie de l'annotation\n","\n","        start_point = max(0, annotation_point - window_size_samples)\n","        end_point = min(len(ecg_df), annotation_point + window_size_samples)\n","\n","        window_data = ecg_df.iloc[start_point:end_point][first_column_name].to_numpy()  # Données dans la fenêtre\n","        if len(window_data) < window_size_samples * 2:\n","            window_data = np.pad(window_data, (0, window_size_samples * 2 - len(window_data)), 'constant')  # Remplissage des données si la fenêtre est incomplète\n","\n","        patient_X.append(window_data)\n","        patient_Y.append(category)\n","\n","    return patient_X, patient_Y\n","\n","# Initialisation des listes pour contenir l'ensemble des données\n","all_X = []\n","all_Y = []\n","\n","data_creation_dir = \"data_creation\"  # Répertoire où se trouvent les fichiers créés\n","\n","# Traitement de chaque patient\n","for patient_number in patient_numbers:\n","    patient_X, patient_Y = process_patient_data(patient_number, data_creation_dir)\n","    all_X.extend(patient_X)\n","    all_Y.extend(patient_Y)\n","\n","X = np.array(all_X)  # Données ECG sous forme de tableau numpy\n","Y = np.array(all_Y)  # Catégories correspondantes sous forme de tableau numpy\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_j1B5afO4muh","executionInfo":{"status":"ok","timestamp":1709462101015,"user_tz":-60,"elapsed":186639,"user":{"displayName":"Paul GILQUIN","userId":"17627275338727361666"}},"outputId":"93029269-f54b-4988-b11b-df9b0d61b892"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Terminé\n"]}]},{"cell_type":"code","source":["print(np.shape(all_X))\n","print(all_X[2][1])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oo0f0rQ04npu","executionInfo":{"status":"ok","timestamp":1709462881859,"user_tz":-60,"elapsed":601,"user":{"displayName":"Paul GILQUIN","userId":"17627275338727361666"}},"outputId":"bb5646d7-106d-4c7c-f3ec-ad64b29ddd17"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["(109494, 2160)\n","-0.145\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":960},"id":"DGeneHHo1-9s","executionInfo":{"status":"error","timestamp":1709396556407,"user_tz":-60,"elapsed":221313,"user":{"displayName":"Paul GILQUIN","userId":"17627275338727361666"}},"outputId":"262ac6fc-44b6-4245-9a1e-ca63202f14fe"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","2738/2738 [==============================] - ETA: 0s - loss: 0.1216 - accuracy: 0.9668\n","Epoch 1: val_accuracy improved from -inf to 0.98004, saving model to best_model.h5\n","2738/2738 [==============================] - 26s 8ms/step - loss: 0.1216 - accuracy: 0.9668 - val_loss: 0.0765 - val_accuracy: 0.9800\n","Epoch 2/10\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["2735/2738 [============================>.] - ETA: 0s - loss: 0.0491 - accuracy: 0.9857\n","Epoch 2: val_accuracy improved from 0.98004 to 0.98324, saving model to best_model.h5\n","2738/2738 [==============================] - 21s 8ms/step - loss: 0.0491 - accuracy: 0.9857 - val_loss: 0.0671 - val_accuracy: 0.9832\n","Epoch 3/10\n","2734/2738 [============================>.] - ETA: 0s - loss: 0.0289 - accuracy: 0.9916\n","Epoch 3: val_accuracy improved from 0.98324 to 0.98397, saving model to best_model.h5\n","2738/2738 [==============================] - 21s 8ms/step - loss: 0.0290 - accuracy: 0.9916 - val_loss: 0.0584 - val_accuracy: 0.9840\n","Epoch 4/10\n","2735/2738 [============================>.] - ETA: 0s - loss: 0.0188 - accuracy: 0.9942\n","Epoch 4: val_accuracy did not improve from 0.98397\n","2738/2738 [==============================] - 21s 7ms/step - loss: 0.0188 - accuracy: 0.9942 - val_loss: 0.0773 - val_accuracy: 0.9839\n","Epoch 5/10\n","2734/2738 [============================>.] - ETA: 0s - loss: 0.0125 - accuracy: 0.9962\n","Epoch 5: val_accuracy improved from 0.98397 to 0.98489, saving model to best_model.h5\n","2738/2738 [==============================] - 20s 7ms/step - loss: 0.0125 - accuracy: 0.9962 - val_loss: 0.0714 - val_accuracy: 0.9849\n","Epoch 6/10\n","2735/2738 [============================>.] - ETA: 0s - loss: 0.0086 - accuracy: 0.9975\n","Epoch 6: val_accuracy did not improve from 0.98489\n","2738/2738 [==============================] - 20s 7ms/step - loss: 0.0086 - accuracy: 0.9975 - val_loss: 0.0866 - val_accuracy: 0.9847\n","Epoch 7/10\n","2737/2738 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9981\n","Epoch 7: val_accuracy improved from 0.98489 to 0.98557, saving model to best_model.h5\n","2738/2738 [==============================] - 23s 8ms/step - loss: 0.0059 - accuracy: 0.9981 - val_loss: 0.0890 - val_accuracy: 0.9856\n","Epoch 8/10\n","2733/2738 [============================>.] - ETA: 0s - loss: 0.0064 - accuracy: 0.9981\n","Epoch 8: val_accuracy did not improve from 0.98557\n","2738/2738 [==============================] - 20s 7ms/step - loss: 0.0064 - accuracy: 0.9981 - val_loss: 0.1210 - val_accuracy: 0.9855\n","Epoch 9/10\n","2737/2738 [============================>.] - ETA: 0s - loss: 0.0045 - accuracy: 0.9986\n","Epoch 9: val_accuracy did not improve from 0.98557\n","2738/2738 [==============================] - 20s 7ms/step - loss: 0.0045 - accuracy: 0.9986 - val_loss: 0.1527 - val_accuracy: 0.9839\n","Epoch 10/10\n","2737/2738 [============================>.] - ETA: 0s - loss: 0.0051 - accuracy: 0.9986\n","Epoch 10: val_accuracy improved from 0.98557 to 0.98575, saving model to best_model.h5\n","2738/2738 [==============================] - 22s 8ms/step - loss: 0.0051 - accuracy: 0.9986 - val_loss: 0.1265 - val_accuracy: 0.9858\n"]},{"output_type":"error","ename":"NameError","evalue":"name 'load_model' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-2ba5cc1a0c8e>\u001b[0m in \u001b[0;36m<cell line: 51>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;31m# Charger le meilleur modèle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'best_model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;31m# Évaluer le modèle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'load_model' is not defined"]}],"source":["import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Flatten, Conv1D, MaxPooling1D\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","from sklearn.metrics import accuracy_score\n","\n","\n","\n","# Séparation des données en ensembles d'entraînement et de test\n","X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n","\n","# Normalisation des données\n","scaler = StandardScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_test = scaler.transform(X_test)\n","from sklearn.preprocessing import LabelEncoder\n","\n","# Mapper les étiquettes de chaînes de caractères à des entiers\n","label_encoder = LabelEncoder()\n","Y_train_encoded = label_encoder.fit_transform(Y_train)\n","Y_test_encoded = label_encoder.transform(Y_test)\n","\n","# Conversion des étiquettes en catégories\n","Y_train = to_categorical(Y_train_encoded)\n","Y_test = to_categorical(Y_test_encoded)\n","\n","\n","# Définition du modèle\n","model = Sequential([\n","    Conv1D(32, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)),\n","    MaxPooling1D(pool_size=2),\n","    Conv1D(64, kernel_size=3, activation='relu'),\n","    MaxPooling1D(pool_size=2),\n","    Flatten(),\n","    Dense(128, activation='relu'),\n","    Dense(Y_train.shape[1], activation='softmax')\n","])\n","\n","# Compiler le modèle\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# Entraîner le modèle\n","checkpoint = ModelCheckpoint('best_model.h5', monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n","callbacks_list = [checkpoint]\n","model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=10, batch_size=32, callbacks=callbacks_list)\n","\n","# Charger le meilleur modèle\n","best_model = load_model('best_model.h5')\n","\n","# Évaluer le modèle\n","Y_pred = best_model.predict(X_test)\n","accuracy = accuracy_score(np.argmax(Y_test, axis=1), np.argmax(Y_pred, axis=1))\n","print(\"Accuracy:\", accuracy)\n"]},{"cell_type":"code","source":["\n","\n","# Charger le meilleur modèle\n","best_model = load_model('best_model.h5')\n","\n","# Évaluer le modèle\n","Y_pred = best_model.predict(X_test)\n","accuracy = accuracy_score(np.argmax(Y_test, axis=1), np.argmax(Y_pred, axis=1))\n","print(\"Accuracy:\", accuracy)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tjIGGoO12uGm","executionInfo":{"status":"ok","timestamp":1709396584126,"user_tz":-60,"elapsed":6561,"user":{"displayName":"Paul GILQUIN","userId":"17627275338727361666"}},"outputId":"d587a09f-873d-422e-858c-b2d5ced68b7b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["685/685 [==============================] - 4s 4ms/step\n","Accuracy: 0.985752774099274\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"k63lF4iu2z5Q"},"execution_count":null,"outputs":[]}]}