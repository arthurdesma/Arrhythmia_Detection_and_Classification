{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fusionné = pd.read_csv('df_fusionné.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fusionné_binaire = df_fusionné.sample(frac=0.2)\n",
    "df_fusionné_binaire.iloc[:, 0] = df_fusionné_binaire.iloc[:, 0].apply(lambda x: 0 if x == 'N' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the occurrences of each class\n",
    "counts = df_fusionné_binaire.iloc[:, 0].value_counts()\n",
    "\n",
    "# Find the number of instances in the minority class\n",
    "min_count = counts.min()\n",
    "\n",
    "# Create balanced DataFrame through undersampling\n",
    "df_balanced_under = pd.concat([\n",
    "    df_fusionné_binaire[df_fusionné_binaire.iloc[:, 0] == 0].sample(min_count),\n",
    "    df_fusionné_binaire[df_fusionné_binaire.iloc[:, 0] == 1].sample(min_count)\n",
    "])\n",
    "\n",
    "# Shuffle the DataFrame to mix the classes\n",
    "df_balanced_under = df_balanced_under.sample(frac=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ColumnName\n",
      "1    7552\n",
      "0    7552\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count occurrences of 0 and 1 in the first column\n",
    "value_counts = df_balanced_under.iloc[:, 0].value_counts()\n",
    "\n",
    "# Display the counts\n",
    "print(value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ColumnName</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>710</th>\n",
       "      <th>711</th>\n",
       "      <th>712</th>\n",
       "      <th>713</th>\n",
       "      <th>714</th>\n",
       "      <th>715</th>\n",
       "      <th>716</th>\n",
       "      <th>717</th>\n",
       "      <th>718</th>\n",
       "      <th>719</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33889</th>\n",
       "      <td>1</td>\n",
       "      <td>0.534183</td>\n",
       "      <td>0.532404</td>\n",
       "      <td>0.530472</td>\n",
       "      <td>0.528452</td>\n",
       "      <td>0.528661</td>\n",
       "      <td>0.529608</td>\n",
       "      <td>0.530814</td>\n",
       "      <td>0.532115</td>\n",
       "      <td>0.532327</td>\n",
       "      <td>...</td>\n",
       "      <td>0.556601</td>\n",
       "      <td>0.576580</td>\n",
       "      <td>0.572279</td>\n",
       "      <td>0.559702</td>\n",
       "      <td>0.542205</td>\n",
       "      <td>0.523533</td>\n",
       "      <td>0.521134</td>\n",
       "      <td>0.524261</td>\n",
       "      <td>0.528782</td>\n",
       "      <td>0.534296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11513</th>\n",
       "      <td>1</td>\n",
       "      <td>0.495040</td>\n",
       "      <td>0.495883</td>\n",
       "      <td>0.496152</td>\n",
       "      <td>0.495715</td>\n",
       "      <td>0.496181</td>\n",
       "      <td>0.496769</td>\n",
       "      <td>0.495641</td>\n",
       "      <td>0.494058</td>\n",
       "      <td>0.494252</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250378</td>\n",
       "      <td>0.239728</td>\n",
       "      <td>0.234463</td>\n",
       "      <td>0.230628</td>\n",
       "      <td>0.225351</td>\n",
       "      <td>0.224546</td>\n",
       "      <td>0.207494</td>\n",
       "      <td>0.208153</td>\n",
       "      <td>0.225726</td>\n",
       "      <td>0.207573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167175</th>\n",
       "      <td>1</td>\n",
       "      <td>0.517586</td>\n",
       "      <td>0.518428</td>\n",
       "      <td>0.519394</td>\n",
       "      <td>0.520493</td>\n",
       "      <td>0.521597</td>\n",
       "      <td>0.522739</td>\n",
       "      <td>0.523979</td>\n",
       "      <td>0.525248</td>\n",
       "      <td>0.526422</td>\n",
       "      <td>...</td>\n",
       "      <td>0.518043</td>\n",
       "      <td>0.518102</td>\n",
       "      <td>0.517992</td>\n",
       "      <td>0.517814</td>\n",
       "      <td>0.517722</td>\n",
       "      <td>0.517645</td>\n",
       "      <td>0.517450</td>\n",
       "      <td>0.517301</td>\n",
       "      <td>0.517110</td>\n",
       "      <td>0.517039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123956</th>\n",
       "      <td>1</td>\n",
       "      <td>0.501004</td>\n",
       "      <td>0.524533</td>\n",
       "      <td>0.546563</td>\n",
       "      <td>0.568909</td>\n",
       "      <td>0.589660</td>\n",
       "      <td>0.605683</td>\n",
       "      <td>0.627932</td>\n",
       "      <td>0.645150</td>\n",
       "      <td>0.626935</td>\n",
       "      <td>...</td>\n",
       "      <td>0.482364</td>\n",
       "      <td>0.483960</td>\n",
       "      <td>0.483293</td>\n",
       "      <td>0.481984</td>\n",
       "      <td>0.482905</td>\n",
       "      <td>0.484445</td>\n",
       "      <td>0.484032</td>\n",
       "      <td>0.484953</td>\n",
       "      <td>0.483466</td>\n",
       "      <td>0.483898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10961</th>\n",
       "      <td>1</td>\n",
       "      <td>0.698745</td>\n",
       "      <td>0.692443</td>\n",
       "      <td>0.708779</td>\n",
       "      <td>0.685442</td>\n",
       "      <td>0.692073</td>\n",
       "      <td>0.699626</td>\n",
       "      <td>0.690838</td>\n",
       "      <td>0.677497</td>\n",
       "      <td>0.675879</td>\n",
       "      <td>...</td>\n",
       "      <td>0.502441</td>\n",
       "      <td>0.505818</td>\n",
       "      <td>0.499260</td>\n",
       "      <td>0.489663</td>\n",
       "      <td>0.493678</td>\n",
       "      <td>0.504173</td>\n",
       "      <td>0.494113</td>\n",
       "      <td>0.494219</td>\n",
       "      <td>0.506399</td>\n",
       "      <td>0.493096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141355</th>\n",
       "      <td>0</td>\n",
       "      <td>0.512862</td>\n",
       "      <td>0.512748</td>\n",
       "      <td>0.512619</td>\n",
       "      <td>0.512476</td>\n",
       "      <td>0.512336</td>\n",
       "      <td>0.512191</td>\n",
       "      <td>0.512038</td>\n",
       "      <td>0.511879</td>\n",
       "      <td>0.511714</td>\n",
       "      <td>...</td>\n",
       "      <td>0.513092</td>\n",
       "      <td>0.513062</td>\n",
       "      <td>0.513047</td>\n",
       "      <td>0.513039</td>\n",
       "      <td>0.513022</td>\n",
       "      <td>0.513003</td>\n",
       "      <td>0.512995</td>\n",
       "      <td>0.512981</td>\n",
       "      <td>0.512970</td>\n",
       "      <td>0.512947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70712</th>\n",
       "      <td>0</td>\n",
       "      <td>0.396079</td>\n",
       "      <td>0.393459</td>\n",
       "      <td>0.388059</td>\n",
       "      <td>0.392337</td>\n",
       "      <td>0.390520</td>\n",
       "      <td>0.388839</td>\n",
       "      <td>0.391488</td>\n",
       "      <td>0.395254</td>\n",
       "      <td>0.394994</td>\n",
       "      <td>...</td>\n",
       "      <td>0.430992</td>\n",
       "      <td>0.429413</td>\n",
       "      <td>0.432892</td>\n",
       "      <td>0.437377</td>\n",
       "      <td>0.441990</td>\n",
       "      <td>0.446018</td>\n",
       "      <td>0.442883</td>\n",
       "      <td>0.433962</td>\n",
       "      <td>0.435085</td>\n",
       "      <td>0.445113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191698</th>\n",
       "      <td>1</td>\n",
       "      <td>0.441102</td>\n",
       "      <td>0.440656</td>\n",
       "      <td>0.440203</td>\n",
       "      <td>0.439760</td>\n",
       "      <td>0.439337</td>\n",
       "      <td>0.438913</td>\n",
       "      <td>0.438511</td>\n",
       "      <td>0.438099</td>\n",
       "      <td>0.437577</td>\n",
       "      <td>...</td>\n",
       "      <td>0.445797</td>\n",
       "      <td>0.445559</td>\n",
       "      <td>0.445211</td>\n",
       "      <td>0.444794</td>\n",
       "      <td>0.444355</td>\n",
       "      <td>0.443879</td>\n",
       "      <td>0.443344</td>\n",
       "      <td>0.442787</td>\n",
       "      <td>0.442191</td>\n",
       "      <td>0.441592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18587</th>\n",
       "      <td>1</td>\n",
       "      <td>0.523958</td>\n",
       "      <td>0.525773</td>\n",
       "      <td>0.527352</td>\n",
       "      <td>0.528821</td>\n",
       "      <td>0.530613</td>\n",
       "      <td>0.532341</td>\n",
       "      <td>0.534081</td>\n",
       "      <td>0.535594</td>\n",
       "      <td>0.536022</td>\n",
       "      <td>...</td>\n",
       "      <td>0.507455</td>\n",
       "      <td>0.506640</td>\n",
       "      <td>0.507495</td>\n",
       "      <td>0.509105</td>\n",
       "      <td>0.510989</td>\n",
       "      <td>0.513165</td>\n",
       "      <td>0.515260</td>\n",
       "      <td>0.517371</td>\n",
       "      <td>0.519687</td>\n",
       "      <td>0.522001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13644</th>\n",
       "      <td>0</td>\n",
       "      <td>0.503153</td>\n",
       "      <td>0.504026</td>\n",
       "      <td>0.508054</td>\n",
       "      <td>0.503114</td>\n",
       "      <td>0.504208</td>\n",
       "      <td>0.505181</td>\n",
       "      <td>0.502315</td>\n",
       "      <td>0.498273</td>\n",
       "      <td>0.496763</td>\n",
       "      <td>...</td>\n",
       "      <td>0.463075</td>\n",
       "      <td>0.464947</td>\n",
       "      <td>0.463246</td>\n",
       "      <td>0.460902</td>\n",
       "      <td>0.458563</td>\n",
       "      <td>0.456666</td>\n",
       "      <td>0.460249</td>\n",
       "      <td>0.468640</td>\n",
       "      <td>0.467697</td>\n",
       "      <td>0.458149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15104 rows × 721 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ColumnName         0         1         2         3         4         5  \\\n",
       "33889           1  0.534183  0.532404  0.530472  0.528452  0.528661  0.529608   \n",
       "11513           1  0.495040  0.495883  0.496152  0.495715  0.496181  0.496769   \n",
       "167175          1  0.517586  0.518428  0.519394  0.520493  0.521597  0.522739   \n",
       "123956          1  0.501004  0.524533  0.546563  0.568909  0.589660  0.605683   \n",
       "10961           1  0.698745  0.692443  0.708779  0.685442  0.692073  0.699626   \n",
       "...           ...       ...       ...       ...       ...       ...       ...   \n",
       "141355          0  0.512862  0.512748  0.512619  0.512476  0.512336  0.512191   \n",
       "70712           0  0.396079  0.393459  0.388059  0.392337  0.390520  0.388839   \n",
       "191698          1  0.441102  0.440656  0.440203  0.439760  0.439337  0.438913   \n",
       "18587           1  0.523958  0.525773  0.527352  0.528821  0.530613  0.532341   \n",
       "13644           0  0.503153  0.504026  0.508054  0.503114  0.504208  0.505181   \n",
       "\n",
       "               6         7         8  ...       710       711       712  \\\n",
       "33889   0.530814  0.532115  0.532327  ...  0.556601  0.576580  0.572279   \n",
       "11513   0.495641  0.494058  0.494252  ...  0.250378  0.239728  0.234463   \n",
       "167175  0.523979  0.525248  0.526422  ...  0.518043  0.518102  0.517992   \n",
       "123956  0.627932  0.645150  0.626935  ...  0.482364  0.483960  0.483293   \n",
       "10961   0.690838  0.677497  0.675879  ...  0.502441  0.505818  0.499260   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "141355  0.512038  0.511879  0.511714  ...  0.513092  0.513062  0.513047   \n",
       "70712   0.391488  0.395254  0.394994  ...  0.430992  0.429413  0.432892   \n",
       "191698  0.438511  0.438099  0.437577  ...  0.445797  0.445559  0.445211   \n",
       "18587   0.534081  0.535594  0.536022  ...  0.507455  0.506640  0.507495   \n",
       "13644   0.502315  0.498273  0.496763  ...  0.463075  0.464947  0.463246   \n",
       "\n",
       "             713       714       715       716       717       718       719  \n",
       "33889   0.559702  0.542205  0.523533  0.521134  0.524261  0.528782  0.534296  \n",
       "11513   0.230628  0.225351  0.224546  0.207494  0.208153  0.225726  0.207573  \n",
       "167175  0.517814  0.517722  0.517645  0.517450  0.517301  0.517110  0.517039  \n",
       "123956  0.481984  0.482905  0.484445  0.484032  0.484953  0.483466  0.483898  \n",
       "10961   0.489663  0.493678  0.504173  0.494113  0.494219  0.506399  0.493096  \n",
       "...          ...       ...       ...       ...       ...       ...       ...  \n",
       "141355  0.513039  0.513022  0.513003  0.512995  0.512981  0.512970  0.512947  \n",
       "70712   0.437377  0.441990  0.446018  0.442883  0.433962  0.435085  0.445113  \n",
       "191698  0.444794  0.444355  0.443879  0.443344  0.442787  0.442191  0.441592  \n",
       "18587   0.509105  0.510989  0.513165  0.515260  0.517371  0.519687  0.522001  \n",
       "13644   0.460902  0.458563  0.456666  0.460249  0.468640  0.467697  0.458149  \n",
       "\n",
       "[15104 rows x 721 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced_under"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_balanced_under.iloc[:, 1:]  \n",
    "y = df_balanced_under.iloc[:, 0] \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_train.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.astype(int)\n",
    "y_test = y_test.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arthurdesmazures/venv-metal/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2024-11-07 16:51:44.855134: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M3 Pro\n",
      "2024-11-07 16:51:44.855159: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 18.00 GB\n",
      "2024-11-07 16:51:44.855164: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 6.00 GB\n",
      "2024-11-07 16:51:44.855334: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-11-07 16:51:44.855343: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, BatchNormalization, MaxPooling1D, Dropout, Flatten, Dense\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "Model = Sequential()\n",
    "\n",
    "Model.add(Conv1D(512, 10, strides=1, padding=\"same\", activation=\"relu\", input_shape=(720, 1)))\n",
    "Model.add(BatchNormalization())\n",
    "Model.add(MaxPooling1D(3, strides=2, padding=\"same\"))\n",
    "\n",
    "Model.add(Conv1D(256, 10, strides=1, padding=\"same\", activation=\"relu\"))\n",
    "Model.add(Dropout(0.2))\n",
    "Model.add(MaxPooling1D(3, strides=2, padding=\"same\"))\n",
    "\n",
    "Model.add(Conv1D(1024, 10, strides=1, padding=\"same\", activation=\"relu\"))\n",
    "Model.add(Dropout(0.2))\n",
    "Model.add(MaxPooling1D(3, strides=2, padding=\"same\"))\n",
    "\n",
    "Model.add(Conv1D(128, 10, strides=1, padding=\"same\", activation=\"relu\"))\n",
    "Model.add(Dropout(0.2))\n",
    "Model.add(MaxPooling1D(3, strides=2, padding=\"same\"))\n",
    "\n",
    "Model.add(Conv1D(64, 10, strides=1, padding=\"same\", activation=\"relu\"))\n",
    "Model.add(Dropout(0.2))\n",
    "Model.add(MaxPooling1D(3, strides=2, padding=\"same\"))\n",
    "\n",
    "Model.add(Conv1D(32, 10, strides=1, padding=\"same\", activation=\"relu\"))\n",
    "Model.add(Dropout(0.2))\n",
    "Model.add(MaxPooling1D(3, strides=2, padding=\"same\"))\n",
    "\n",
    "Model.add(Flatten())\n",
    "Model.add(Dense(1024, activation='relu'))\n",
    "Model.add(Dropout(0.2))\n",
    "\n",
    "Model.add(Dense(512, activation='relu'))\n",
    "Model.add(Dropout(0.2))\n",
    "\n",
    "Model.add(Dense(64, activation='relu'))\n",
    "Model.add(Dropout(0.2))\n",
    "\n",
    "Model.add(Dense(units=1, activation='sigmoid'))  # Use 'sigmoid' for binary classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">720</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,632</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">720</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">360</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">360</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,310,976</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">360</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">180</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">180</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,622,464</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">180</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,310,848</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">81,984</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">394,240</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">524,800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,832</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m720\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │         \u001b[38;5;34m5,632\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m720\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m360\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m360\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │     \u001b[38;5;34m1,310,976\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m360\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m180\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m180\u001b[0m, \u001b[38;5;34m1024\u001b[0m)      │     \u001b[38;5;34m2,622,464\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m180\u001b[0m, \u001b[38;5;34m1024\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_2 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m90\u001b[0m, \u001b[38;5;34m1024\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m90\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │     \u001b[38;5;34m1,310,848\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m90\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_3 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m45\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_4 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m45\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m81,984\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m45\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_4 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_5 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │        \u001b[38;5;34m20,512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_5 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m384\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │       \u001b[38;5;34m394,240\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m524,800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m32,832\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,306,401</span> (24.06 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,306,401\u001b[0m (24.06 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,305,377</span> (24.05 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,305,377\u001b[0m (24.05 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> (4.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,024\u001b[0m (4.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(Model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks\n",
    "Early_Stopper = tf.keras.callbacks.EarlyStopping(monitor=\"loss\", patience=3, mode=\"min\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "Model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-07 16:51:45.811329: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 135ms/step - accuracy: 0.6818 - loss: 0.6004 - val_accuracy: 0.5717 - val_loss: 0.7488\n",
      "Epoch 2/70\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 130ms/step - accuracy: 0.7922 - loss: 0.4570 - val_accuracy: 0.6425 - val_loss: 0.6671\n",
      "Epoch 3/70\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 133ms/step - accuracy: 0.8209 - loss: 0.4137 - val_accuracy: 0.7259 - val_loss: 0.5154\n",
      "Epoch 4/70\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 133ms/step - accuracy: 0.8293 - loss: 0.3988 - val_accuracy: 0.7630 - val_loss: 0.5041\n",
      "Epoch 5/70\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 133ms/step - accuracy: 0.8521 - loss: 0.3547 - val_accuracy: 0.6438 - val_loss: 1.2364\n",
      "Epoch 6/70\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 133ms/step - accuracy: 0.8576 - loss: 0.3422 - val_accuracy: 0.7699 - val_loss: 0.4798\n",
      "Epoch 7/70\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 133ms/step - accuracy: 0.8667 - loss: 0.3332 - val_accuracy: 0.5766 - val_loss: 1.0698\n",
      "Epoch 8/70\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 132ms/step - accuracy: 0.8690 - loss: 0.3185 - val_accuracy: 0.7951 - val_loss: 0.4640\n",
      "Epoch 9/70\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 130ms/step - accuracy: 0.8749 - loss: 0.3039 - val_accuracy: 0.8176 - val_loss: 0.4159\n",
      "Epoch 10/70\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 130ms/step - accuracy: 0.8777 - loss: 0.3070 - val_accuracy: 0.8580 - val_loss: 0.3387\n",
      "Epoch 11/70\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 130ms/step - accuracy: 0.8807 - loss: 0.3025 - val_accuracy: 0.7335 - val_loss: 0.5618\n",
      "Epoch 12/70\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 130ms/step - accuracy: 0.8817 - loss: 0.2847 - val_accuracy: 0.7934 - val_loss: 0.4644\n",
      "Epoch 13/70\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 131ms/step - accuracy: 0.8795 - loss: 0.2998 - val_accuracy: 0.5369 - val_loss: 0.9017\n",
      "Epoch 14/70\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 129ms/step - accuracy: 0.8831 - loss: 0.2859 - val_accuracy: 0.6342 - val_loss: 0.8610\n",
      "Epoch 15/70\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 129ms/step - accuracy: 0.8846 - loss: 0.2919 - val_accuracy: 0.6812 - val_loss: 0.6400\n",
      "Epoch 16/70\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 129ms/step - accuracy: 0.8749 - loss: 0.2980 - val_accuracy: 0.8679 - val_loss: 0.3290\n",
      "Epoch 17/70\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 129ms/step - accuracy: 0.8837 - loss: 0.2818 - val_accuracy: 0.8782 - val_loss: 0.3306\n",
      "Epoch 18/70\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 128ms/step - accuracy: 0.8900 - loss: 0.2689 - val_accuracy: 0.8709 - val_loss: 0.3044\n",
      "Epoch 19/70\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 130ms/step - accuracy: 0.8931 - loss: 0.2613 - val_accuracy: 0.8858 - val_loss: 0.2907\n",
      "Epoch 20/70\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 129ms/step - accuracy: 0.8960 - loss: 0.2502 - val_accuracy: 0.8117 - val_loss: 0.4392\n",
      "Epoch 21/70\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 129ms/step - accuracy: 0.8926 - loss: 0.2528 - val_accuracy: 0.6902 - val_loss: 0.8783\n",
      "Epoch 22/70\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 129ms/step - accuracy: 0.8911 - loss: 0.2667 - val_accuracy: 0.8262 - val_loss: 0.4207\n",
      "Epoch 23/70\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 128ms/step - accuracy: 0.8981 - loss: 0.2515 - val_accuracy: 0.8838 - val_loss: 0.2888\n",
      "Epoch 24/70\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 129ms/step - accuracy: 0.8998 - loss: 0.2405 - val_accuracy: 0.8186 - val_loss: 0.4337\n",
      "Epoch 25/70\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 131ms/step - accuracy: 0.8969 - loss: 0.2460 - val_accuracy: 0.8706 - val_loss: 0.3228\n",
      "Epoch 26/70\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 128ms/step - accuracy: 0.8973 - loss: 0.2465 - val_accuracy: 0.7865 - val_loss: 0.5038\n",
      "Epoch 27/70\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 130ms/step - accuracy: 0.8971 - loss: 0.2534 - val_accuracy: 0.8815 - val_loss: 0.3044\n",
      "Epoch 28/70\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 130ms/step - accuracy: 0.9075 - loss: 0.2326 - val_accuracy: 0.8815 - val_loss: 0.3100\n",
      "Epoch 29/70\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 131ms/step - accuracy: 0.9037 - loss: 0.2307 - val_accuracy: 0.8987 - val_loss: 0.2698\n",
      "Epoch 30/70\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 133ms/step - accuracy: 0.9010 - loss: 0.2343 - val_accuracy: 0.8878 - val_loss: 0.2941\n",
      "Epoch 31/70\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 131ms/step - accuracy: 0.9050 - loss: 0.2384 - val_accuracy: 0.8775 - val_loss: 0.3245\n",
      "Epoch 32/70\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 130ms/step - accuracy: 0.9080 - loss: 0.2314 - val_accuracy: 0.8881 - val_loss: 0.2824\n",
      "Epoch 33/70\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 131ms/step - accuracy: 0.9048 - loss: 0.2254 - val_accuracy: 0.8921 - val_loss: 0.2754\n",
      "Epoch 34/70\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 130ms/step - accuracy: 0.9061 - loss: 0.2368 - val_accuracy: 0.8967 - val_loss: 0.2616\n",
      "Epoch 35/70\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 132ms/step - accuracy: 0.9082 - loss: 0.2167 - val_accuracy: 0.8391 - val_loss: 0.4082\n",
      "Epoch 36/70\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 131ms/step - accuracy: 0.9093 - loss: 0.2212 - val_accuracy: 0.8944 - val_loss: 0.2860\n",
      "Epoch 37/70\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 133ms/step - accuracy: 0.9089 - loss: 0.2148 - val_accuracy: 0.5965 - val_loss: 1.3528\n",
      "Epoch 38/70\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 131ms/step - accuracy: 0.9062 - loss: 0.2216 - val_accuracy: 0.8954 - val_loss: 0.2705\n",
      "Epoch 39/70\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 134ms/step - accuracy: 0.9089 - loss: 0.2202 - val_accuracy: 0.8901 - val_loss: 0.2862\n",
      "Epoch 40/70\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 132ms/step - accuracy: 0.9139 - loss: 0.2093 - val_accuracy: 0.8841 - val_loss: 0.3079\n",
      "Epoch 41/70\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 134ms/step - accuracy: 0.9137 - loss: 0.2131 - val_accuracy: 0.8818 - val_loss: 0.3076\n",
      "Epoch 42/70\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 132ms/step - accuracy: 0.9109 - loss: 0.2281 - val_accuracy: 0.8613 - val_loss: 0.3762\n",
      "Epoch 43/70\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 131ms/step - accuracy: 0.9131 - loss: 0.2102 - val_accuracy: 0.8408 - val_loss: 0.3937\n",
      "Epoch 44/70\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 132ms/step - accuracy: 0.9108 - loss: 0.2320 - val_accuracy: 0.7534 - val_loss: 0.4952\n",
      "Epoch 45/70\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 129ms/step - accuracy: 0.9068 - loss: 0.2311 - val_accuracy: 0.8901 - val_loss: 0.3046\n",
      "Epoch 46/70\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 130ms/step - accuracy: 0.9030 - loss: 0.2377 - val_accuracy: 0.8908 - val_loss: 0.2846\n"
     ]
    }
   ],
   "source": [
    "Conv1D_Model = Model.fit(X_train, y_train, epochs=70, validation_data=(X_test, y_test), callbacks=[Early_Stopper])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "Model.save('Conv1D_Model.h5')  # Saves the model to a HDF5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.8922 - loss: 0.2839\n",
      "LOSS:  0.2846\n",
      "ACCURACY:  0.8908\n"
     ]
    }
   ],
   "source": [
    "Model_Results = Model.evaluate(X_test,y_test)\n",
    "print(\"LOSS:  \" + \"%.4f\" % Model_Results[0])\n",
    "print(\"ACCURACY:  \" + \"%.4f\" % Model_Results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step\n"
     ]
    }
   ],
   "source": [
    "# Assuming your model is named 'Model'\n",
    "y_pred_probs = Model.predict(X_test)\n",
    "y_pred = (y_pred_probs > 0.5).astype(\"int32\")  # Convert probabilities to binary labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[1332  173]\n",
      " [ 157 1359]]\n",
      "Precision: 0.89\n",
      "Recall: 0.90\n",
      "F1 Score: 0.89\n",
      "ROC AUC Score: 0.96\n",
      "Log Loss: 0.28\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score, roc_curve, log_loss\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "# Precision\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "\n",
    "# Recall\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "\n",
    "# F1 Score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "\n",
    "# ROC-AUC Score\n",
    "roc_auc = roc_auc_score(y_test, y_pred_probs)\n",
    "print(f\"ROC AUC Score: {roc_auc:.2f}\")\n",
    "\n",
    "# Now, you can calculate the log loss\n",
    "logloss = log_loss(y_test, y_pred_probs)\n",
    "print(f\"Log Loss: {logloss:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix:\n",
    " [[1359  157]\n",
    " [ 167 1354]]\n",
    "Precision: 0.90\n",
    "Recall: 0.89\n",
    "F1 Score: 0.89\n",
    "ROC AUC Score: 0.96\n",
    "Log Loss: 0.30\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-metal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
