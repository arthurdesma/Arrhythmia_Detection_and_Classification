{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fusionné = pd.read_csv('df_fusionné.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fusionné_binaire = df_fusionné.sample(frac=0.2)\n",
    "df_fusionné_binaire.iloc[:, 0] = df_fusionné_binaire.iloc[:, 0].apply(lambda x: 0 if x == 'N' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the occurrences of each class\n",
    "counts = df_fusionné_binaire.iloc[:, 0].value_counts()\n",
    "\n",
    "# Find the number of instances in the minority class\n",
    "min_count = counts.min()\n",
    "\n",
    "# Create balanced DataFrame through undersampling\n",
    "df_balanced_under = pd.concat([\n",
    "    df_fusionné_binaire[df_fusionné_binaire.iloc[:, 0] == 0].sample(min_count),\n",
    "    df_fusionné_binaire[df_fusionné_binaire.iloc[:, 0] == 1].sample(min_count)\n",
    "])\n",
    "\n",
    "# Shuffle the DataFrame to mix the classes\n",
    "df_balanced_under = df_balanced_under.sample(frac=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ColumnName\n",
      "1    7594\n",
      "0    7594\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count occurrences of 0 and 1 in the first column\n",
    "value_counts = df_balanced_under.iloc[:, 0].value_counts()\n",
    "\n",
    "# Display the counts\n",
    "print(value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ColumnName</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>710</th>\n",
       "      <th>711</th>\n",
       "      <th>712</th>\n",
       "      <th>713</th>\n",
       "      <th>714</th>\n",
       "      <th>715</th>\n",
       "      <th>716</th>\n",
       "      <th>717</th>\n",
       "      <th>718</th>\n",
       "      <th>719</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10306</th>\n",
       "      <td>1</td>\n",
       "      <td>0.473727</td>\n",
       "      <td>0.473003</td>\n",
       "      <td>0.472581</td>\n",
       "      <td>0.472528</td>\n",
       "      <td>0.472420</td>\n",
       "      <td>0.472363</td>\n",
       "      <td>0.472604</td>\n",
       "      <td>0.472895</td>\n",
       "      <td>0.472716</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500201</td>\n",
       "      <td>0.500912</td>\n",
       "      <td>0.499307</td>\n",
       "      <td>0.496620</td>\n",
       "      <td>0.493829</td>\n",
       "      <td>0.490669</td>\n",
       "      <td>0.487041</td>\n",
       "      <td>0.483392</td>\n",
       "      <td>0.479287</td>\n",
       "      <td>0.475414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79377</th>\n",
       "      <td>1</td>\n",
       "      <td>0.442109</td>\n",
       "      <td>0.442227</td>\n",
       "      <td>0.442360</td>\n",
       "      <td>0.442506</td>\n",
       "      <td>0.442654</td>\n",
       "      <td>0.442806</td>\n",
       "      <td>0.442970</td>\n",
       "      <td>0.443138</td>\n",
       "      <td>0.443303</td>\n",
       "      <td>...</td>\n",
       "      <td>0.441852</td>\n",
       "      <td>0.441881</td>\n",
       "      <td>0.441893</td>\n",
       "      <td>0.441901</td>\n",
       "      <td>0.441918</td>\n",
       "      <td>0.441939</td>\n",
       "      <td>0.441952</td>\n",
       "      <td>0.441971</td>\n",
       "      <td>0.441989</td>\n",
       "      <td>0.442020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87909</th>\n",
       "      <td>0</td>\n",
       "      <td>0.457614</td>\n",
       "      <td>0.457547</td>\n",
       "      <td>0.457487</td>\n",
       "      <td>0.457422</td>\n",
       "      <td>0.457330</td>\n",
       "      <td>0.457234</td>\n",
       "      <td>0.457124</td>\n",
       "      <td>0.457018</td>\n",
       "      <td>0.456977</td>\n",
       "      <td>...</td>\n",
       "      <td>0.457978</td>\n",
       "      <td>0.457954</td>\n",
       "      <td>0.457922</td>\n",
       "      <td>0.457888</td>\n",
       "      <td>0.457849</td>\n",
       "      <td>0.457808</td>\n",
       "      <td>0.457775</td>\n",
       "      <td>0.457742</td>\n",
       "      <td>0.457708</td>\n",
       "      <td>0.457670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59269</th>\n",
       "      <td>0</td>\n",
       "      <td>0.499488</td>\n",
       "      <td>0.502200</td>\n",
       "      <td>0.508321</td>\n",
       "      <td>0.514962</td>\n",
       "      <td>0.515455</td>\n",
       "      <td>0.513917</td>\n",
       "      <td>0.511896</td>\n",
       "      <td>0.509571</td>\n",
       "      <td>0.509583</td>\n",
       "      <td>...</td>\n",
       "      <td>0.663403</td>\n",
       "      <td>0.672461</td>\n",
       "      <td>0.647249</td>\n",
       "      <td>0.610461</td>\n",
       "      <td>0.565314</td>\n",
       "      <td>0.519394</td>\n",
       "      <td>0.503355</td>\n",
       "      <td>0.499251</td>\n",
       "      <td>0.496536</td>\n",
       "      <td>0.497669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83276</th>\n",
       "      <td>0</td>\n",
       "      <td>0.421630</td>\n",
       "      <td>0.419092</td>\n",
       "      <td>0.424596</td>\n",
       "      <td>0.411681</td>\n",
       "      <td>0.412613</td>\n",
       "      <td>0.414459</td>\n",
       "      <td>0.408233</td>\n",
       "      <td>0.400631</td>\n",
       "      <td>0.402279</td>\n",
       "      <td>...</td>\n",
       "      <td>0.322368</td>\n",
       "      <td>0.325182</td>\n",
       "      <td>0.322451</td>\n",
       "      <td>0.318273</td>\n",
       "      <td>0.319940</td>\n",
       "      <td>0.324675</td>\n",
       "      <td>0.322086</td>\n",
       "      <td>0.324533</td>\n",
       "      <td>0.332747</td>\n",
       "      <td>0.329460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29130</th>\n",
       "      <td>1</td>\n",
       "      <td>0.479325</td>\n",
       "      <td>0.477139</td>\n",
       "      <td>0.473028</td>\n",
       "      <td>0.478520</td>\n",
       "      <td>0.476689</td>\n",
       "      <td>0.474606</td>\n",
       "      <td>0.476684</td>\n",
       "      <td>0.479893</td>\n",
       "      <td>0.480013</td>\n",
       "      <td>...</td>\n",
       "      <td>0.543481</td>\n",
       "      <td>0.539800</td>\n",
       "      <td>0.539175</td>\n",
       "      <td>0.538958</td>\n",
       "      <td>0.538728</td>\n",
       "      <td>0.538028</td>\n",
       "      <td>0.531784</td>\n",
       "      <td>0.520752</td>\n",
       "      <td>0.519351</td>\n",
       "      <td>0.527062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185183</th>\n",
       "      <td>1</td>\n",
       "      <td>0.502949</td>\n",
       "      <td>0.520786</td>\n",
       "      <td>0.522212</td>\n",
       "      <td>0.519065</td>\n",
       "      <td>0.520744</td>\n",
       "      <td>0.523007</td>\n",
       "      <td>0.522358</td>\n",
       "      <td>0.521022</td>\n",
       "      <td>0.521855</td>\n",
       "      <td>...</td>\n",
       "      <td>0.510629</td>\n",
       "      <td>0.511303</td>\n",
       "      <td>0.510981</td>\n",
       "      <td>0.510082</td>\n",
       "      <td>0.510665</td>\n",
       "      <td>0.511013</td>\n",
       "      <td>0.508793</td>\n",
       "      <td>0.506979</td>\n",
       "      <td>0.499352</td>\n",
       "      <td>0.490820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155399</th>\n",
       "      <td>0</td>\n",
       "      <td>0.518201</td>\n",
       "      <td>0.513647</td>\n",
       "      <td>0.525294</td>\n",
       "      <td>0.508029</td>\n",
       "      <td>0.514353</td>\n",
       "      <td>0.522053</td>\n",
       "      <td>0.518115</td>\n",
       "      <td>0.511143</td>\n",
       "      <td>0.512431</td>\n",
       "      <td>...</td>\n",
       "      <td>0.416023</td>\n",
       "      <td>0.409964</td>\n",
       "      <td>0.397140</td>\n",
       "      <td>0.382828</td>\n",
       "      <td>0.379605</td>\n",
       "      <td>0.382319</td>\n",
       "      <td>0.370250</td>\n",
       "      <td>0.366482</td>\n",
       "      <td>0.375528</td>\n",
       "      <td>0.367415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166793</th>\n",
       "      <td>1</td>\n",
       "      <td>0.480011</td>\n",
       "      <td>0.465132</td>\n",
       "      <td>0.465820</td>\n",
       "      <td>0.471780</td>\n",
       "      <td>0.473930</td>\n",
       "      <td>0.475792</td>\n",
       "      <td>0.481365</td>\n",
       "      <td>0.487511</td>\n",
       "      <td>0.488762</td>\n",
       "      <td>...</td>\n",
       "      <td>0.503300</td>\n",
       "      <td>0.501458</td>\n",
       "      <td>0.501840</td>\n",
       "      <td>0.502561</td>\n",
       "      <td>0.503458</td>\n",
       "      <td>0.504086</td>\n",
       "      <td>0.500615</td>\n",
       "      <td>0.494928</td>\n",
       "      <td>0.493215</td>\n",
       "      <td>0.492629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189396</th>\n",
       "      <td>0</td>\n",
       "      <td>0.429810</td>\n",
       "      <td>0.428800</td>\n",
       "      <td>0.427864</td>\n",
       "      <td>0.427062</td>\n",
       "      <td>0.426341</td>\n",
       "      <td>0.425667</td>\n",
       "      <td>0.425143</td>\n",
       "      <td>0.424653</td>\n",
       "      <td>0.423850</td>\n",
       "      <td>...</td>\n",
       "      <td>0.445497</td>\n",
       "      <td>0.445141</td>\n",
       "      <td>0.444050</td>\n",
       "      <td>0.442575</td>\n",
       "      <td>0.441031</td>\n",
       "      <td>0.439328</td>\n",
       "      <td>0.437391</td>\n",
       "      <td>0.435406</td>\n",
       "      <td>0.433249</td>\n",
       "      <td>0.431155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15188 rows × 721 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ColumnName         0         1         2         3         4         5  \\\n",
       "10306           1  0.473727  0.473003  0.472581  0.472528  0.472420  0.472363   \n",
       "79377           1  0.442109  0.442227  0.442360  0.442506  0.442654  0.442806   \n",
       "87909           0  0.457614  0.457547  0.457487  0.457422  0.457330  0.457234   \n",
       "59269           0  0.499488  0.502200  0.508321  0.514962  0.515455  0.513917   \n",
       "83276           0  0.421630  0.419092  0.424596  0.411681  0.412613  0.414459   \n",
       "...           ...       ...       ...       ...       ...       ...       ...   \n",
       "29130           1  0.479325  0.477139  0.473028  0.478520  0.476689  0.474606   \n",
       "185183          1  0.502949  0.520786  0.522212  0.519065  0.520744  0.523007   \n",
       "155399          0  0.518201  0.513647  0.525294  0.508029  0.514353  0.522053   \n",
       "166793          1  0.480011  0.465132  0.465820  0.471780  0.473930  0.475792   \n",
       "189396          0  0.429810  0.428800  0.427864  0.427062  0.426341  0.425667   \n",
       "\n",
       "               6         7         8  ...       710       711       712  \\\n",
       "10306   0.472604  0.472895  0.472716  ...  0.500201  0.500912  0.499307   \n",
       "79377   0.442970  0.443138  0.443303  ...  0.441852  0.441881  0.441893   \n",
       "87909   0.457124  0.457018  0.456977  ...  0.457978  0.457954  0.457922   \n",
       "59269   0.511896  0.509571  0.509583  ...  0.663403  0.672461  0.647249   \n",
       "83276   0.408233  0.400631  0.402279  ...  0.322368  0.325182  0.322451   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "29130   0.476684  0.479893  0.480013  ...  0.543481  0.539800  0.539175   \n",
       "185183  0.522358  0.521022  0.521855  ...  0.510629  0.511303  0.510981   \n",
       "155399  0.518115  0.511143  0.512431  ...  0.416023  0.409964  0.397140   \n",
       "166793  0.481365  0.487511  0.488762  ...  0.503300  0.501458  0.501840   \n",
       "189396  0.425143  0.424653  0.423850  ...  0.445497  0.445141  0.444050   \n",
       "\n",
       "             713       714       715       716       717       718       719  \n",
       "10306   0.496620  0.493829  0.490669  0.487041  0.483392  0.479287  0.475414  \n",
       "79377   0.441901  0.441918  0.441939  0.441952  0.441971  0.441989  0.442020  \n",
       "87909   0.457888  0.457849  0.457808  0.457775  0.457742  0.457708  0.457670  \n",
       "59269   0.610461  0.565314  0.519394  0.503355  0.499251  0.496536  0.497669  \n",
       "83276   0.318273  0.319940  0.324675  0.322086  0.324533  0.332747  0.329460  \n",
       "...          ...       ...       ...       ...       ...       ...       ...  \n",
       "29130   0.538958  0.538728  0.538028  0.531784  0.520752  0.519351  0.527062  \n",
       "185183  0.510082  0.510665  0.511013  0.508793  0.506979  0.499352  0.490820  \n",
       "155399  0.382828  0.379605  0.382319  0.370250  0.366482  0.375528  0.367415  \n",
       "166793  0.502561  0.503458  0.504086  0.500615  0.494928  0.493215  0.492629  \n",
       "189396  0.442575  0.441031  0.439328  0.437391  0.435406  0.433249  0.431155  \n",
       "\n",
       "[15188 rows x 721 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced_under"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_balanced_under.iloc[:, 1:]  \n",
    "y = df_balanced_under.iloc[:, 0] \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_train.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.astype(int)\n",
    "y_test = y_test.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n",
      "2024-03-13 17:45:02.233283: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M3 Pro\n",
      "2024-03-13 17:45:02.233300: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 18.00 GB\n",
      "2024-03-13 17:45:02.233304: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 6.00 GB\n",
      "2024-03-13 17:45:02.233321: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-03-13 17:45:02.233331: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, BatchNormalization, MaxPooling1D, Dropout, Flatten, Dense\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "Model = Sequential()\n",
    "\n",
    "Model.add(Conv1D(512, 10, strides=1, padding=\"same\", activation=\"relu\", input_shape=(720, 1)))\n",
    "Model.add(BatchNormalization())\n",
    "Model.add(MaxPooling1D(3, strides=2, padding=\"same\"))\n",
    "\n",
    "Model.add(Conv1D(256, 10, strides=1, padding=\"same\", activation=\"relu\"))\n",
    "Model.add(Dropout(0.3))\n",
    "Model.add(MaxPooling1D(3, strides=2, padding=\"same\"))\n",
    "\n",
    "Model.add(Conv1D(128, 10, strides=1, padding=\"same\", activation=\"relu\"))\n",
    "Model.add(Dropout(0.3))\n",
    "Model.add(MaxPooling1D(3, strides=2, padding=\"same\"))\n",
    "\n",
    "Model.add(Conv1D(64, 10, strides=1, padding=\"same\", activation=\"relu\"))\n",
    "Model.add(Dropout(0.3))\n",
    "Model.add(MaxPooling1D(3, strides=2, padding=\"same\"))\n",
    "\n",
    "Model.add(Conv1D(32, 10, strides=1, padding=\"same\", activation=\"relu\"))\n",
    "Model.add(Dropout(0.3))\n",
    "Model.add(MaxPooling1D(3, strides=2, padding=\"same\"))\n",
    "\n",
    "Model.add(Flatten())\n",
    "Model.add(Dense(1024, activation='relu'))\n",
    "Model.add(Dropout(0.3))\n",
    "\n",
    "Model.add(Dense(512, activation='relu'))\n",
    "Model.add(Dropout(0.3))\n",
    "\n",
    "Model.add(Dense(64, activation='relu'))\n",
    "Model.add(Dropout(0.3))\n",
    "\n",
    "Model.add(Dense(units=1, activation='sigmoid'))  # Use 'sigmoid' for binary classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">720</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,632</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">720</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">360</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">360</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,310,976</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">360</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">180</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">180</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">327,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">180</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">81,984</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">736</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">754,688</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">524,800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,832</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m720\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │         \u001b[38;5;34m5,632\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m720\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m360\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m360\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │     \u001b[38;5;34m1,310,976\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m360\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m180\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m180\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │       \u001b[38;5;34m327,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m180\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_2 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m90\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m90\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m81,984\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m90\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_3 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m45\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_4 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m45\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │        \u001b[38;5;34m20,512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m45\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_4 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m736\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │       \u001b[38;5;34m754,688\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m524,800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m32,832\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,061,345</span> (11.68 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,061,345\u001b[0m (11.68 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,060,321</span> (11.67 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,060,321\u001b[0m (11.67 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> (4.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,024\u001b[0m (4.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(Model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks\n",
    "Early_Stopper = tf.keras.callbacks.EarlyStopping(monitor=\"loss\", patience=3, mode=\"min\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "Model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-13 17:45:03.008345: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 110ms/step - accuracy: 0.6661 - loss: 0.6062 - val_accuracy: 0.6254 - val_loss: 0.6456\n",
      "Epoch 2/70\n",
      "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 110ms/step - accuracy: 0.7742 - loss: 0.4941 - val_accuracy: 0.6159 - val_loss: 0.6670\n",
      "Epoch 3/70\n",
      "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 111ms/step - accuracy: 0.7977 - loss: 0.4486 - val_accuracy: 0.5760 - val_loss: 0.7479\n",
      "Epoch 4/70\n",
      "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 111ms/step - accuracy: 0.8194 - loss: 0.4091 - val_accuracy: 0.7729 - val_loss: 0.4868\n",
      "Epoch 5/70\n",
      "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 112ms/step - accuracy: 0.8356 - loss: 0.3858 - val_accuracy: 0.6995 - val_loss: 0.5523\n",
      "Epoch 6/70\n",
      "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 111ms/step - accuracy: 0.8451 - loss: 0.3593 - val_accuracy: 0.6771 - val_loss: 0.5707\n",
      "Epoch 7/70\n",
      "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 112ms/step - accuracy: 0.8485 - loss: 0.3501 - val_accuracy: 0.6761 - val_loss: 0.6145\n",
      "Epoch 8/70\n",
      "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 112ms/step - accuracy: 0.8535 - loss: 0.3477 - val_accuracy: 0.7966 - val_loss: 0.4147\n",
      "Epoch 9/70\n",
      "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 112ms/step - accuracy: 0.8632 - loss: 0.3221 - val_accuracy: 0.7117 - val_loss: 0.5908\n",
      "Epoch 10/70\n",
      "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 111ms/step - accuracy: 0.8653 - loss: 0.3148 - val_accuracy: 0.8318 - val_loss: 0.3683\n",
      "Epoch 11/70\n",
      "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 112ms/step - accuracy: 0.8673 - loss: 0.3087 - val_accuracy: 0.7775 - val_loss: 0.4599\n",
      "Epoch 12/70\n",
      "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 112ms/step - accuracy: 0.8735 - loss: 0.2940 - val_accuracy: 0.5227 - val_loss: 0.6985\n",
      "Epoch 13/70\n",
      "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 112ms/step - accuracy: 0.8695 - loss: 0.2981 - val_accuracy: 0.6284 - val_loss: 0.6455\n",
      "Epoch 14/70\n",
      "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 111ms/step - accuracy: 0.8779 - loss: 0.2822 - val_accuracy: 0.6731 - val_loss: 0.6127\n",
      "Epoch 15/70\n",
      "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 111ms/step - accuracy: 0.8849 - loss: 0.2869 - val_accuracy: 0.7956 - val_loss: 0.4372\n",
      "Epoch 16/70\n",
      "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 112ms/step - accuracy: 0.8769 - loss: 0.2891 - val_accuracy: 0.8045 - val_loss: 0.4290\n",
      "Epoch 17/70\n",
      "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 112ms/step - accuracy: 0.8766 - loss: 0.2849 - val_accuracy: 0.6261 - val_loss: 0.5850\n",
      "Epoch 18/70\n",
      "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 112ms/step - accuracy: 0.8811 - loss: 0.2739 - val_accuracy: 0.8311 - val_loss: 0.3686\n",
      "Epoch 19/70\n",
      "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 112ms/step - accuracy: 0.8822 - loss: 0.2657 - val_accuracy: 0.7189 - val_loss: 0.5343\n",
      "Epoch 20/70\n",
      "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 112ms/step - accuracy: 0.8863 - loss: 0.2611 - val_accuracy: 0.7943 - val_loss: 0.4670\n",
      "Epoch 21/70\n",
      "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 112ms/step - accuracy: 0.8886 - loss: 0.2605 - val_accuracy: 0.7995 - val_loss: 0.4135\n",
      "Epoch 22/70\n",
      "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 112ms/step - accuracy: 0.8829 - loss: 0.2611 - val_accuracy: 0.5905 - val_loss: 0.7506\n",
      "Epoch 23/70\n",
      "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 112ms/step - accuracy: 0.8824 - loss: 0.2753 - val_accuracy: 0.7676 - val_loss: 0.4791\n",
      "Epoch 24/70\n",
      "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 112ms/step - accuracy: 0.8866 - loss: 0.2598 - val_accuracy: 0.8107 - val_loss: 0.4369\n",
      "Epoch 25/70\n",
      "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 112ms/step - accuracy: 0.8881 - loss: 0.2586 - val_accuracy: 0.8394 - val_loss: 0.3630\n",
      "Epoch 26/70\n",
      "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 112ms/step - accuracy: 0.8937 - loss: 0.2496 - val_accuracy: 0.7785 - val_loss: 0.5162\n",
      "Epoch 27/70\n",
      "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 112ms/step - accuracy: 0.9021 - loss: 0.2343 - val_accuracy: 0.7390 - val_loss: 0.6585\n",
      "Epoch 28/70\n",
      "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 112ms/step - accuracy: 0.8940 - loss: 0.2511 - val_accuracy: 0.8315 - val_loss: 0.3578\n",
      "Epoch 29/70\n",
      "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 112ms/step - accuracy: 0.9006 - loss: 0.2304 - val_accuracy: 0.8407 - val_loss: 0.3633\n",
      "Epoch 30/70\n",
      "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 112ms/step - accuracy: 0.9046 - loss: 0.2226 - val_accuracy: 0.7693 - val_loss: 0.5130\n",
      "Epoch 31/70\n",
      "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 112ms/step - accuracy: 0.9092 - loss: 0.2244 - val_accuracy: 0.8548 - val_loss: 0.3345\n",
      "Epoch 32/70\n",
      "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 113ms/step - accuracy: 0.9099 - loss: 0.2161 - val_accuracy: 0.8035 - val_loss: 0.4606\n",
      "Epoch 33/70\n",
      "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 112ms/step - accuracy: 0.9096 - loss: 0.2239 - val_accuracy: 0.8805 - val_loss: 0.2957\n",
      "Epoch 34/70\n",
      "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 113ms/step - accuracy: 0.9075 - loss: 0.2225 - val_accuracy: 0.8720 - val_loss: 0.2942\n",
      "Epoch 35/70\n",
      "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 112ms/step - accuracy: 0.9097 - loss: 0.2060 - val_accuracy: 0.8581 - val_loss: 0.3154\n",
      "Epoch 36/70\n",
      "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 113ms/step - accuracy: 0.9130 - loss: 0.2086 - val_accuracy: 0.8752 - val_loss: 0.3226\n",
      "Epoch 37/70\n",
      "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 112ms/step - accuracy: 0.9113 - loss: 0.2130 - val_accuracy: 0.6422 - val_loss: 0.6080\n",
      "Epoch 38/70\n",
      "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 112ms/step - accuracy: 0.9153 - loss: 0.2118 - val_accuracy: 0.8288 - val_loss: 0.3770\n"
     ]
    }
   ],
   "source": [
    "Conv1D_Model = Model.fit(X_train, y_train, epochs=70, validation_data=(X_test, y_test), callbacks=[Early_Stopper])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "Model.save('Conv1D_Model.h5')  # Saves the model to a HDF5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.8278 - loss: 0.3839\n",
      "LOSS:  0.3770\n",
      "ACCURACY:  0.8288\n"
     ]
    }
   ],
   "source": [
    "Model_Results = Model.evaluate(X_test,y_test)\n",
    "print(\"LOSS:  \" + \"%.4f\" % Model_Results[0])\n",
    "print(\"ACCURACY:  \" + \"%.4f\" % Model_Results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step\n"
     ]
    }
   ],
   "source": [
    "# Assuming your model is named 'Model'\n",
    "y_pred_probs = Model.predict(X_test)\n",
    "y_pred = (y_pred_probs > 0.5).astype(\"int32\")  # Convert probabilities to binary labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[1359  155]\n",
      " [ 365 1159]]\n",
      "Precision: 0.88\n",
      "Recall: 0.76\n",
      "F1 Score: 0.82\n",
      "ROC AUC Score: 0.92\n",
      "Log Loss: 0.38\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score, roc_curve, log_loss\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "# Precision\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "\n",
    "# Recall\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "\n",
    "# F1 Score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "\n",
    "# ROC-AUC Score\n",
    "roc_auc = roc_auc_score(y_test, y_pred_probs)\n",
    "print(f\"ROC AUC Score: {roc_auc:.2f}\")\n",
    "\n",
    "# Now, you can calculate the log loss\n",
    "logloss = log_loss(y_test, y_pred_probs)\n",
    "print(f\"Log Loss: {logloss:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix:\n",
    " [[1456  106]\n",
    " [ 640  834]]\n",
    "Precision: 0.89\n",
    "Recall: 0.57\n",
    "F1 Score: 0.69\n",
    "ROC AUC Score: 0.86\n",
    "Log Loss: 0.65\n",
    "\n",
    "Confusion Matrix:\n",
    " [[1357  127]\n",
    " [ 325 1187]]\n",
    "Precision: 0.90\n",
    "Recall: 0.79\n",
    "F1 Score: 0.84\n",
    "ROC AUC Score: 0.95\n",
    "Log Loss: 0.33\n",
    "\n",
    "Confusion Matrix:\n",
    " [[1401  104]\n",
    " [ 947  576]]\n",
    "Precision: 0.85\n",
    "Recall: 0.38\n",
    "F1 Score: 0.52\n",
    "ROC AUC Score: 0.81\n",
    "Log Loss: 0.64\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix:\n",
    " [[1425  117]\n",
    " [ 375 1122]]\n",
    "Precision: 0.91\n",
    "Recall: 0.75\n",
    "F1 Score: 0.82\n",
    "ROC AUC Score: 0.93\n",
    "Log Loss: 0.41\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-metal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
