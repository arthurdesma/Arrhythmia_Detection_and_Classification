{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fusionné = pd.read_csv('df_fusionné.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fusionné_binaire = df_fusionné.sample(frac=1)\n",
    "df_fusionné_binaire.iloc[:, 0] = df_fusionné_binaire.iloc[:, 0].apply(lambda x: 0 if x == 'N' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152910    0\n",
       "103081    1\n",
       "3312      0\n",
       "209827    0\n",
       "132849    1\n",
       "         ..\n",
       "132559    0\n",
       "48762     0\n",
       "206305    1\n",
       "62924     0\n",
       "90080     0\n",
       "Name: ColumnName, Length: 218988, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fusionné_binaire.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ColumnName\n",
      "0    181262\n",
      "1     37726\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "counts = df_fusionné_binaire.iloc[:, 0].value_counts()\n",
    "print(counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37726\n"
     ]
    }
   ],
   "source": [
    "counts = df_fusionné_binaire.iloc[:, 0].value_counts()\n",
    "min_count = counts.min()\n",
    "print(min_count)\n",
    "\n",
    "# Create balanced DataFrame through undersampling\n",
    "df_balanced_under = pd.concat([\n",
    "    df_fusionné_binaire[df_fusionné_binaire.iloc[:, 0] == 0].sample(min_count),\n",
    "    df_fusionné_binaire[df_fusionné_binaire.iloc[:, 0] == 1].sample(min_count)\n",
    "])\n",
    "\n",
    "# Shuffle the DataFrame to mix the classes\n",
    "df_balanced_under = df_balanced_under.sample(frac=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ColumnName\n",
      "1    37726\n",
      "0    37726\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "value_counts = df_balanced_under.iloc[:, 0].value_counts()\n",
    "\n",
    "print(value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ColumnName</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>350</th>\n",
       "      <th>351</th>\n",
       "      <th>352</th>\n",
       "      <th>353</th>\n",
       "      <th>354</th>\n",
       "      <th>355</th>\n",
       "      <th>356</th>\n",
       "      <th>357</th>\n",
       "      <th>358</th>\n",
       "      <th>359</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33883</th>\n",
       "      <td>1</td>\n",
       "      <td>0.524332</td>\n",
       "      <td>0.523519</td>\n",
       "      <td>0.522840</td>\n",
       "      <td>0.522103</td>\n",
       "      <td>0.521060</td>\n",
       "      <td>0.520088</td>\n",
       "      <td>0.518900</td>\n",
       "      <td>0.517950</td>\n",
       "      <td>0.518592</td>\n",
       "      <td>...</td>\n",
       "      <td>0.523748</td>\n",
       "      <td>0.523459</td>\n",
       "      <td>0.523381</td>\n",
       "      <td>0.523418</td>\n",
       "      <td>0.523353</td>\n",
       "      <td>0.523320</td>\n",
       "      <td>0.523610</td>\n",
       "      <td>0.523936</td>\n",
       "      <td>0.524395</td>\n",
       "      <td>0.524784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165469</th>\n",
       "      <td>1</td>\n",
       "      <td>0.524397</td>\n",
       "      <td>0.524890</td>\n",
       "      <td>0.525035</td>\n",
       "      <td>0.524813</td>\n",
       "      <td>0.524713</td>\n",
       "      <td>0.524533</td>\n",
       "      <td>0.524087</td>\n",
       "      <td>0.523515</td>\n",
       "      <td>0.523002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.502151</td>\n",
       "      <td>0.500948</td>\n",
       "      <td>0.502154</td>\n",
       "      <td>0.504466</td>\n",
       "      <td>0.506914</td>\n",
       "      <td>0.509731</td>\n",
       "      <td>0.512900</td>\n",
       "      <td>0.516067</td>\n",
       "      <td>0.519654</td>\n",
       "      <td>0.523019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125746</th>\n",
       "      <td>1</td>\n",
       "      <td>0.465820</td>\n",
       "      <td>0.465053</td>\n",
       "      <td>0.464420</td>\n",
       "      <td>0.463693</td>\n",
       "      <td>0.462437</td>\n",
       "      <td>0.461140</td>\n",
       "      <td>0.459683</td>\n",
       "      <td>0.458403</td>\n",
       "      <td>0.458617</td>\n",
       "      <td>...</td>\n",
       "      <td>0.463185</td>\n",
       "      <td>0.463625</td>\n",
       "      <td>0.464026</td>\n",
       "      <td>0.464400</td>\n",
       "      <td>0.464613</td>\n",
       "      <td>0.464773</td>\n",
       "      <td>0.465169</td>\n",
       "      <td>0.465545</td>\n",
       "      <td>0.465946</td>\n",
       "      <td>0.466235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2964</th>\n",
       "      <td>1</td>\n",
       "      <td>0.465875</td>\n",
       "      <td>0.465613</td>\n",
       "      <td>0.465337</td>\n",
       "      <td>0.465044</td>\n",
       "      <td>0.464760</td>\n",
       "      <td>0.464482</td>\n",
       "      <td>0.464191</td>\n",
       "      <td>0.463908</td>\n",
       "      <td>0.463672</td>\n",
       "      <td>...</td>\n",
       "      <td>0.467303</td>\n",
       "      <td>0.466974</td>\n",
       "      <td>0.466774</td>\n",
       "      <td>0.466635</td>\n",
       "      <td>0.466497</td>\n",
       "      <td>0.466379</td>\n",
       "      <td>0.466292</td>\n",
       "      <td>0.466206</td>\n",
       "      <td>0.466150</td>\n",
       "      <td>0.466080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193155</th>\n",
       "      <td>1</td>\n",
       "      <td>0.333802</td>\n",
       "      <td>0.379021</td>\n",
       "      <td>0.431971</td>\n",
       "      <td>0.474295</td>\n",
       "      <td>0.489330</td>\n",
       "      <td>0.491791</td>\n",
       "      <td>0.502508</td>\n",
       "      <td>0.512559</td>\n",
       "      <td>0.518016</td>\n",
       "      <td>...</td>\n",
       "      <td>0.480592</td>\n",
       "      <td>0.477782</td>\n",
       "      <td>0.482018</td>\n",
       "      <td>0.488689</td>\n",
       "      <td>0.486472</td>\n",
       "      <td>0.479526</td>\n",
       "      <td>0.489620</td>\n",
       "      <td>0.493203</td>\n",
       "      <td>0.479897</td>\n",
       "      <td>0.495819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135052</th>\n",
       "      <td>0</td>\n",
       "      <td>0.491348</td>\n",
       "      <td>0.489482</td>\n",
       "      <td>0.493135</td>\n",
       "      <td>0.488505</td>\n",
       "      <td>0.489969</td>\n",
       "      <td>0.491537</td>\n",
       "      <td>0.489914</td>\n",
       "      <td>0.487344</td>\n",
       "      <td>0.486767</td>\n",
       "      <td>...</td>\n",
       "      <td>0.442149</td>\n",
       "      <td>0.453441</td>\n",
       "      <td>0.456887</td>\n",
       "      <td>0.457804</td>\n",
       "      <td>0.460188</td>\n",
       "      <td>0.462146</td>\n",
       "      <td>0.464045</td>\n",
       "      <td>0.468676</td>\n",
       "      <td>0.462849</td>\n",
       "      <td>0.447728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161532</th>\n",
       "      <td>0</td>\n",
       "      <td>0.466462</td>\n",
       "      <td>0.465983</td>\n",
       "      <td>0.465599</td>\n",
       "      <td>0.465206</td>\n",
       "      <td>0.464592</td>\n",
       "      <td>0.463994</td>\n",
       "      <td>0.463301</td>\n",
       "      <td>0.462724</td>\n",
       "      <td>0.462950</td>\n",
       "      <td>...</td>\n",
       "      <td>0.467486</td>\n",
       "      <td>0.467892</td>\n",
       "      <td>0.467945</td>\n",
       "      <td>0.467848</td>\n",
       "      <td>0.467649</td>\n",
       "      <td>0.467388</td>\n",
       "      <td>0.467260</td>\n",
       "      <td>0.467139</td>\n",
       "      <td>0.467005</td>\n",
       "      <td>0.466838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78489</th>\n",
       "      <td>1</td>\n",
       "      <td>0.306167</td>\n",
       "      <td>0.293601</td>\n",
       "      <td>0.271532</td>\n",
       "      <td>0.277037</td>\n",
       "      <td>0.267186</td>\n",
       "      <td>0.259111</td>\n",
       "      <td>0.263594</td>\n",
       "      <td>0.272466</td>\n",
       "      <td>0.273434</td>\n",
       "      <td>...</td>\n",
       "      <td>0.443980</td>\n",
       "      <td>0.436003</td>\n",
       "      <td>0.440463</td>\n",
       "      <td>0.449053</td>\n",
       "      <td>0.447320</td>\n",
       "      <td>0.441164</td>\n",
       "      <td>0.449768</td>\n",
       "      <td>0.450769</td>\n",
       "      <td>0.443677</td>\n",
       "      <td>0.451415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206634</th>\n",
       "      <td>1</td>\n",
       "      <td>0.474960</td>\n",
       "      <td>0.474675</td>\n",
       "      <td>0.474329</td>\n",
       "      <td>0.473946</td>\n",
       "      <td>0.473658</td>\n",
       "      <td>0.473390</td>\n",
       "      <td>0.473104</td>\n",
       "      <td>0.472820</td>\n",
       "      <td>0.472490</td>\n",
       "      <td>...</td>\n",
       "      <td>0.474916</td>\n",
       "      <td>0.474664</td>\n",
       "      <td>0.474618</td>\n",
       "      <td>0.474659</td>\n",
       "      <td>0.474688</td>\n",
       "      <td>0.474737</td>\n",
       "      <td>0.474829</td>\n",
       "      <td>0.474911</td>\n",
       "      <td>0.475040</td>\n",
       "      <td>0.475134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31061</th>\n",
       "      <td>1</td>\n",
       "      <td>0.531129</td>\n",
       "      <td>0.530771</td>\n",
       "      <td>0.529959</td>\n",
       "      <td>0.528688</td>\n",
       "      <td>0.527554</td>\n",
       "      <td>0.526324</td>\n",
       "      <td>0.524780</td>\n",
       "      <td>0.523110</td>\n",
       "      <td>0.521544</td>\n",
       "      <td>...</td>\n",
       "      <td>0.508124</td>\n",
       "      <td>0.508027</td>\n",
       "      <td>0.509796</td>\n",
       "      <td>0.512395</td>\n",
       "      <td>0.514929</td>\n",
       "      <td>0.517673</td>\n",
       "      <td>0.520835</td>\n",
       "      <td>0.523912</td>\n",
       "      <td>0.527336</td>\n",
       "      <td>0.530410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75452 rows × 361 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ColumnName         0         1         2         3         4         5  \\\n",
       "33883           1  0.524332  0.523519  0.522840  0.522103  0.521060  0.520088   \n",
       "165469          1  0.524397  0.524890  0.525035  0.524813  0.524713  0.524533   \n",
       "125746          1  0.465820  0.465053  0.464420  0.463693  0.462437  0.461140   \n",
       "2964            1  0.465875  0.465613  0.465337  0.465044  0.464760  0.464482   \n",
       "193155          1  0.333802  0.379021  0.431971  0.474295  0.489330  0.491791   \n",
       "...           ...       ...       ...       ...       ...       ...       ...   \n",
       "135052          0  0.491348  0.489482  0.493135  0.488505  0.489969  0.491537   \n",
       "161532          0  0.466462  0.465983  0.465599  0.465206  0.464592  0.463994   \n",
       "78489           1  0.306167  0.293601  0.271532  0.277037  0.267186  0.259111   \n",
       "206634          1  0.474960  0.474675  0.474329  0.473946  0.473658  0.473390   \n",
       "31061           1  0.531129  0.530771  0.529959  0.528688  0.527554  0.526324   \n",
       "\n",
       "               6         7         8  ...       350       351       352  \\\n",
       "33883   0.518900  0.517950  0.518592  ...  0.523748  0.523459  0.523381   \n",
       "165469  0.524087  0.523515  0.523002  ...  0.502151  0.500948  0.502154   \n",
       "125746  0.459683  0.458403  0.458617  ...  0.463185  0.463625  0.464026   \n",
       "2964    0.464191  0.463908  0.463672  ...  0.467303  0.466974  0.466774   \n",
       "193155  0.502508  0.512559  0.518016  ...  0.480592  0.477782  0.482018   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "135052  0.489914  0.487344  0.486767  ...  0.442149  0.453441  0.456887   \n",
       "161532  0.463301  0.462724  0.462950  ...  0.467486  0.467892  0.467945   \n",
       "78489   0.263594  0.272466  0.273434  ...  0.443980  0.436003  0.440463   \n",
       "206634  0.473104  0.472820  0.472490  ...  0.474916  0.474664  0.474618   \n",
       "31061   0.524780  0.523110  0.521544  ...  0.508124  0.508027  0.509796   \n",
       "\n",
       "             353       354       355       356       357       358       359  \n",
       "33883   0.523418  0.523353  0.523320  0.523610  0.523936  0.524395  0.524784  \n",
       "165469  0.504466  0.506914  0.509731  0.512900  0.516067  0.519654  0.523019  \n",
       "125746  0.464400  0.464613  0.464773  0.465169  0.465545  0.465946  0.466235  \n",
       "2964    0.466635  0.466497  0.466379  0.466292  0.466206  0.466150  0.466080  \n",
       "193155  0.488689  0.486472  0.479526  0.489620  0.493203  0.479897  0.495819  \n",
       "...          ...       ...       ...       ...       ...       ...       ...  \n",
       "135052  0.457804  0.460188  0.462146  0.464045  0.468676  0.462849  0.447728  \n",
       "161532  0.467848  0.467649  0.467388  0.467260  0.467139  0.467005  0.466838  \n",
       "78489   0.449053  0.447320  0.441164  0.449768  0.450769  0.443677  0.451415  \n",
       "206634  0.474659  0.474688  0.474737  0.474829  0.474911  0.475040  0.475134  \n",
       "31061   0.512395  0.514929  0.517673  0.520835  0.523912  0.527336  0.530410  \n",
       "\n",
       "[75452 rows x 361 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced_under"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_balanced_under.iloc[:, 1:]  \n",
    "y = df_balanced_under.iloc[:, 0] \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_train.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.astype(int)\n",
    "y_test = y_test.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n",
      "2024-04-28 18:14:50.421786: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M3 Pro\n",
      "2024-04-28 18:14:50.421808: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 18.00 GB\n",
      "2024-04-28 18:14:50.421814: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 6.00 GB\n",
      "2024-04-28 18:14:50.421844: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-04-28 18:14:50.421854: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, BatchNormalization, MaxPooling1D, Dropout, Flatten, Dense\n",
    "from keras.optimizers import Adam, Adadelta\n",
    "\n",
    "Model = Sequential()\n",
    "\n",
    "Model.add(Conv1D(512, 10, strides=1, padding=\"same\", activation=\"relu\", input_shape=(360, 1)))\n",
    "Model.add(BatchNormalization())\n",
    "Model.add(MaxPooling1D(3, strides=2, padding=\"same\"))\n",
    "\n",
    "Model.add(Conv1D(256, 10, strides=1, padding=\"same\", activation=\"relu\"))\n",
    "Model.add(Dropout(0.2))\n",
    "Model.add(MaxPooling1D(3, strides=2, padding=\"same\"))\n",
    "\n",
    "Model.add(Conv1D(128, 10, strides=1, padding=\"same\", activation=\"relu\"))\n",
    "Model.add(Dropout(0.2))\n",
    "Model.add(MaxPooling1D(3, strides=2, padding=\"same\"))\n",
    "\n",
    "Model.add(Conv1D(64, 10, strides=1, padding=\"same\", activation=\"relu\"))\n",
    "Model.add(Dropout(0.2))\n",
    "Model.add(MaxPooling1D(3, strides=2, padding=\"same\"))\n",
    "\n",
    "Model.add(Conv1D(32, 10, strides=1, padding=\"same\", activation=\"relu\"))\n",
    "Model.add(Dropout(0.2))\n",
    "Model.add(MaxPooling1D(3, strides=2, padding=\"same\"))\n",
    "\n",
    "Model.add(Flatten())\n",
    "Model.add(Dense(1024, activation='relu'))\n",
    "Model.add(Dropout(0.2))\n",
    "\n",
    "Model.add(Dense(512, activation='relu'))\n",
    "Model.add(Dropout(0.2))\n",
    "\n",
    "Model.add(Dense(64, activation='relu'))\n",
    "Model.add(Dropout(0.2))\n",
    "\n",
    "Model.add(Dense(units=1, activation='sigmoid'))  # Use 'sigmoid' for binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">360</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,632</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">360</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">180</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">180</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,310,976</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">180</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">327,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">81,984</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">394,240</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">524,800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,832</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m360\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │         \u001b[38;5;34m5,632\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m360\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m180\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m180\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │     \u001b[38;5;34m1,310,976\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m180\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m90\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m90\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │       \u001b[38;5;34m327,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m90\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_2 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m45\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m45\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m81,984\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m45\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_3 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_4 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │        \u001b[38;5;34m20,512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_4 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m384\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │       \u001b[38;5;34m394,240\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m524,800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m32,832\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,700,897</span> (10.30 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,700,897\u001b[0m (10.30 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,699,873</span> (10.30 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,699,873\u001b[0m (10.30 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> (4.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,024\u001b[0m (4.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(Model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks\n",
    "Early_Stopper = tf.keras.callbacks.EarlyStopping(monitor=\"loss\", patience=3, mode=\"min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-28 18:14:51.285496: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1887/1887\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 89ms/step - accuracy: 0.7530 - loss: 0.5018 - val_accuracy: 0.7839 - val_loss: 0.4420\n",
      "Epoch 2/70\n",
      "\u001b[1m1887/1887\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 87ms/step - accuracy: 0.8490 - loss: 0.3626 - val_accuracy: 0.7175 - val_loss: 0.6234\n",
      "Epoch 3/70\n",
      "\u001b[1m1887/1887\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 87ms/step - accuracy: 0.8797 - loss: 0.3062 - val_accuracy: 0.6879 - val_loss: 0.7616\n",
      "Epoch 4/70\n",
      "\u001b[1m1887/1887\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 88ms/step - accuracy: 0.8932 - loss: 0.2773 - val_accuracy: 0.8686 - val_loss: 0.3148\n",
      "Epoch 5/70\n",
      "\u001b[1m1887/1887\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 88ms/step - accuracy: 0.8970 - loss: 0.2655 - val_accuracy: 0.8279 - val_loss: 0.4072\n",
      "Epoch 6/70\n",
      "\u001b[1m1887/1887\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 89ms/step - accuracy: 0.9040 - loss: 0.2529 - val_accuracy: 0.7322 - val_loss: 0.5344\n",
      "Epoch 7/70\n",
      "\u001b[1m1887/1887\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 89ms/step - accuracy: 0.9089 - loss: 0.2444 - val_accuracy: 0.8903 - val_loss: 0.2867\n",
      "Epoch 8/70\n",
      "\u001b[1m1887/1887\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 89ms/step - accuracy: 0.9087 - loss: 0.2421 - val_accuracy: 0.9079 - val_loss: 0.2424\n",
      "Epoch 9/70\n",
      "\u001b[1m1887/1887\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 89ms/step - accuracy: 0.9119 - loss: 0.2304 - val_accuracy: 0.8453 - val_loss: 0.3798\n",
      "Epoch 10/70\n",
      "\u001b[1m1887/1887\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 90ms/step - accuracy: 0.9149 - loss: 0.2257 - val_accuracy: 0.9057 - val_loss: 0.2622\n",
      "Epoch 11/70\n",
      "\u001b[1m1887/1887\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 90ms/step - accuracy: 0.9183 - loss: 0.2174 - val_accuracy: 0.9134 - val_loss: 0.2382\n",
      "Epoch 12/70\n",
      "\u001b[1m1887/1887\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 90ms/step - accuracy: 0.9199 - loss: 0.2149 - val_accuracy: 0.9252 - val_loss: 0.2093\n",
      "Epoch 13/70\n",
      "\u001b[1m1887/1887\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 90ms/step - accuracy: 0.9216 - loss: 0.2100 - val_accuracy: 0.9147 - val_loss: 0.2249\n",
      "Epoch 14/70\n",
      "\u001b[1m1887/1887\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 90ms/step - accuracy: 0.9222 - loss: 0.2079 - val_accuracy: 0.8906 - val_loss: 0.2899\n",
      "Epoch 15/70\n",
      "\u001b[1m1887/1887\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 90ms/step - accuracy: 0.9231 - loss: 0.2042 - val_accuracy: 0.8724 - val_loss: 0.3236\n",
      "Epoch 16/70\n",
      "\u001b[1m1887/1887\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 90ms/step - accuracy: 0.9230 - loss: 0.2037 - val_accuracy: 0.8781 - val_loss: 0.3433\n",
      "Epoch 17/70\n",
      "\u001b[1m1887/1887\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 91ms/step - accuracy: 0.9235 - loss: 0.2028 - val_accuracy: 0.9119 - val_loss: 0.2402\n",
      "Epoch 18/70\n",
      "\u001b[1m1887/1887\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 90ms/step - accuracy: 0.9234 - loss: 0.2009 - val_accuracy: 0.9005 - val_loss: 0.2649\n",
      "Epoch 19/70\n",
      "\u001b[1m1887/1887\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 92ms/step - accuracy: 0.9196 - loss: 0.4942 - val_accuracy: 0.9208 - val_loss: 0.2401\n",
      "Epoch 20/70\n",
      "\u001b[1m1887/1887\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 90ms/step - accuracy: 0.9163 - loss: 0.2290 - val_accuracy: 0.9239 - val_loss: 0.2138\n"
     ]
    }
   ],
   "source": [
    "Conv1D_Model = Model.fit(X_train, y_train, epochs=70, validation_data=(X_test, y_test), callbacks=[Early_Stopper])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "Model.save('Conv1D.h5')  # Saves the model to a HDF5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.9250 - loss: 0.2108\n",
      "LOSS:  0.2138\n",
      "ACCURACY:  0.9239\n"
     ]
    }
   ],
   "source": [
    "Model_Results = Model.evaluate(X_test,y_test)\n",
    "print(\"LOSS:  \" + \"%.4f\" % Model_Results[0])\n",
    "print(\"ACCURACY:  \" + \"%.4f\" % Model_Results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step\n"
     ]
    }
   ],
   "source": [
    "# Assuming your model is named 'Model'\n",
    "y_pred_probs = Model.predict(X_test)\n",
    "y_pred = (y_pred_probs > 0.5).astype(\"int32\")  # Convert probabilities to binary labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[6831  675]\n",
      " [ 473 7112]]\n",
      "Precision: 0.91\n",
      "Recall: 0.94\n",
      "F1 Score: 0.93\n",
      "ROC AUC Score: 0.97\n",
      "Log Loss: 0.21\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score, roc_curve, log_loss\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "# Precision\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "\n",
    "# Recall\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "\n",
    "# F1 Score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "\n",
    "# ROC-AUC Score\n",
    "roc_auc = roc_auc_score(y_test, y_pred_probs)\n",
    "print(f\"ROC AUC Score: {roc_auc:.2f}\")\n",
    "\n",
    "# Now, you can calculate the log loss\n",
    "logloss = log_loss(y_test, y_pred_probs)\n",
    "print(f\"Log Loss: {logloss:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (229432189.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[21], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    Confusion Matrix:\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Confusion Matrix:\n",
    " [[6969  525]\n",
    " [ 667 6930]]\n",
    "Precision: 0.93\n",
    "Recall: 0.91\n",
    "F1 Score: 0.92\n",
    "ROC AUC Score: 0.98\n",
    "Log Loss: 0.21\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-metal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
