{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fusionné = pd.read_csv('df_fusionné.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fusionné_binaire = df_fusionné.sample(frac=1)\n",
    "df_fusionné_binaire.iloc[:, 0] = df_fusionné_binaire.iloc[:, 0].apply(lambda x: 0 if x == 'N' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the occurrences of each class\n",
    "counts = df_fusionné_binaire.iloc[:, 0].value_counts()\n",
    "\n",
    "# Find the number of instances in the minority class\n",
    "min_count = counts.min()\n",
    "\n",
    "# Create balanced DataFrame through undersampling\n",
    "df_balanced_under = pd.concat([\n",
    "    df_fusionné_binaire[df_fusionné_binaire.iloc[:, 0] == 0].sample(min_count),\n",
    "    df_fusionné_binaire[df_fusionné_binaire.iloc[:, 0] == 1].sample(min_count)\n",
    "])\n",
    "\n",
    "# Shuffle the DataFrame to mix the classes\n",
    "df_balanced_under = df_balanced_under.sample(frac=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ColumnName\n",
      "0    37726\n",
      "1    37726\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count occurrences of 0 and 1 in the first column\n",
    "value_counts = df_balanced_under.iloc[:, 0].value_counts()\n",
    "\n",
    "# Display the counts\n",
    "print(value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ColumnName</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>710</th>\n",
       "      <th>711</th>\n",
       "      <th>712</th>\n",
       "      <th>713</th>\n",
       "      <th>714</th>\n",
       "      <th>715</th>\n",
       "      <th>716</th>\n",
       "      <th>717</th>\n",
       "      <th>718</th>\n",
       "      <th>719</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>144606</th>\n",
       "      <td>0</td>\n",
       "      <td>0.492344</td>\n",
       "      <td>0.491184</td>\n",
       "      <td>0.489745</td>\n",
       "      <td>0.487921</td>\n",
       "      <td>0.485960</td>\n",
       "      <td>0.483926</td>\n",
       "      <td>0.481543</td>\n",
       "      <td>0.479170</td>\n",
       "      <td>0.477686</td>\n",
       "      <td>...</td>\n",
       "      <td>0.476936</td>\n",
       "      <td>0.477933</td>\n",
       "      <td>0.479488</td>\n",
       "      <td>0.481302</td>\n",
       "      <td>0.482871</td>\n",
       "      <td>0.484442</td>\n",
       "      <td>0.486517</td>\n",
       "      <td>0.488512</td>\n",
       "      <td>0.490699</td>\n",
       "      <td>0.492546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35913</th>\n",
       "      <td>0</td>\n",
       "      <td>0.434227</td>\n",
       "      <td>0.420098</td>\n",
       "      <td>0.409422</td>\n",
       "      <td>0.416141</td>\n",
       "      <td>0.412705</td>\n",
       "      <td>0.409911</td>\n",
       "      <td>0.415799</td>\n",
       "      <td>0.424124</td>\n",
       "      <td>0.424607</td>\n",
       "      <td>...</td>\n",
       "      <td>0.514241</td>\n",
       "      <td>0.509941</td>\n",
       "      <td>0.512667</td>\n",
       "      <td>0.517600</td>\n",
       "      <td>0.516781</td>\n",
       "      <td>0.513453</td>\n",
       "      <td>0.517247</td>\n",
       "      <td>0.516293</td>\n",
       "      <td>0.512578</td>\n",
       "      <td>0.517158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167257</th>\n",
       "      <td>1</td>\n",
       "      <td>0.569916</td>\n",
       "      <td>0.565686</td>\n",
       "      <td>0.568726</td>\n",
       "      <td>0.559476</td>\n",
       "      <td>0.560414</td>\n",
       "      <td>0.561986</td>\n",
       "      <td>0.558652</td>\n",
       "      <td>0.554033</td>\n",
       "      <td>0.552767</td>\n",
       "      <td>...</td>\n",
       "      <td>0.512338</td>\n",
       "      <td>0.513878</td>\n",
       "      <td>0.511832</td>\n",
       "      <td>0.508585</td>\n",
       "      <td>0.509804</td>\n",
       "      <td>0.513054</td>\n",
       "      <td>0.508800</td>\n",
       "      <td>0.507294</td>\n",
       "      <td>0.511190</td>\n",
       "      <td>0.507380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153815</th>\n",
       "      <td>1</td>\n",
       "      <td>0.510099</td>\n",
       "      <td>0.511281</td>\n",
       "      <td>0.512505</td>\n",
       "      <td>0.513753</td>\n",
       "      <td>0.514973</td>\n",
       "      <td>0.516206</td>\n",
       "      <td>0.517439</td>\n",
       "      <td>0.518695</td>\n",
       "      <td>0.520078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.499950</td>\n",
       "      <td>0.500905</td>\n",
       "      <td>0.501804</td>\n",
       "      <td>0.502709</td>\n",
       "      <td>0.503645</td>\n",
       "      <td>0.504611</td>\n",
       "      <td>0.505641</td>\n",
       "      <td>0.506713</td>\n",
       "      <td>0.507812</td>\n",
       "      <td>0.508941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163561</th>\n",
       "      <td>0</td>\n",
       "      <td>0.512019</td>\n",
       "      <td>0.512167</td>\n",
       "      <td>0.512318</td>\n",
       "      <td>0.512468</td>\n",
       "      <td>0.512607</td>\n",
       "      <td>0.512744</td>\n",
       "      <td>0.512874</td>\n",
       "      <td>0.513004</td>\n",
       "      <td>0.513159</td>\n",
       "      <td>...</td>\n",
       "      <td>0.510597</td>\n",
       "      <td>0.510765</td>\n",
       "      <td>0.510893</td>\n",
       "      <td>0.511012</td>\n",
       "      <td>0.511133</td>\n",
       "      <td>0.511256</td>\n",
       "      <td>0.511401</td>\n",
       "      <td>0.511554</td>\n",
       "      <td>0.511710</td>\n",
       "      <td>0.511868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204256</th>\n",
       "      <td>1</td>\n",
       "      <td>0.488184</td>\n",
       "      <td>0.482630</td>\n",
       "      <td>0.475795</td>\n",
       "      <td>0.469250</td>\n",
       "      <td>0.468647</td>\n",
       "      <td>0.470310</td>\n",
       "      <td>0.473017</td>\n",
       "      <td>0.476345</td>\n",
       "      <td>0.477462</td>\n",
       "      <td>...</td>\n",
       "      <td>0.499591</td>\n",
       "      <td>0.500172</td>\n",
       "      <td>0.499322</td>\n",
       "      <td>0.497942</td>\n",
       "      <td>0.495688</td>\n",
       "      <td>0.493248</td>\n",
       "      <td>0.492444</td>\n",
       "      <td>0.491773</td>\n",
       "      <td>0.492283</td>\n",
       "      <td>0.492536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205101</th>\n",
       "      <td>1</td>\n",
       "      <td>0.509249</td>\n",
       "      <td>0.509337</td>\n",
       "      <td>0.509400</td>\n",
       "      <td>0.509459</td>\n",
       "      <td>0.509542</td>\n",
       "      <td>0.509615</td>\n",
       "      <td>0.509704</td>\n",
       "      <td>0.509772</td>\n",
       "      <td>0.509697</td>\n",
       "      <td>...</td>\n",
       "      <td>0.508193</td>\n",
       "      <td>0.508274</td>\n",
       "      <td>0.508448</td>\n",
       "      <td>0.508634</td>\n",
       "      <td>0.508814</td>\n",
       "      <td>0.508979</td>\n",
       "      <td>0.509066</td>\n",
       "      <td>0.509122</td>\n",
       "      <td>0.509155</td>\n",
       "      <td>0.509177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141353</th>\n",
       "      <td>0</td>\n",
       "      <td>0.512035</td>\n",
       "      <td>0.515310</td>\n",
       "      <td>0.516407</td>\n",
       "      <td>0.516952</td>\n",
       "      <td>0.515331</td>\n",
       "      <td>0.512972</td>\n",
       "      <td>0.509823</td>\n",
       "      <td>0.506638</td>\n",
       "      <td>0.506042</td>\n",
       "      <td>...</td>\n",
       "      <td>0.485838</td>\n",
       "      <td>0.485401</td>\n",
       "      <td>0.479142</td>\n",
       "      <td>0.473306</td>\n",
       "      <td>0.487065</td>\n",
       "      <td>0.505589</td>\n",
       "      <td>0.518955</td>\n",
       "      <td>0.530188</td>\n",
       "      <td>0.523752</td>\n",
       "      <td>0.511607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139862</th>\n",
       "      <td>0</td>\n",
       "      <td>0.473653</td>\n",
       "      <td>0.473915</td>\n",
       "      <td>0.474195</td>\n",
       "      <td>0.474498</td>\n",
       "      <td>0.474809</td>\n",
       "      <td>0.475130</td>\n",
       "      <td>0.475468</td>\n",
       "      <td>0.475811</td>\n",
       "      <td>0.476132</td>\n",
       "      <td>...</td>\n",
       "      <td>0.472542</td>\n",
       "      <td>0.472606</td>\n",
       "      <td>0.472683</td>\n",
       "      <td>0.472769</td>\n",
       "      <td>0.472875</td>\n",
       "      <td>0.472991</td>\n",
       "      <td>0.473090</td>\n",
       "      <td>0.473197</td>\n",
       "      <td>0.473306</td>\n",
       "      <td>0.473435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212270</th>\n",
       "      <td>0</td>\n",
       "      <td>0.488235</td>\n",
       "      <td>0.487344</td>\n",
       "      <td>0.486847</td>\n",
       "      <td>0.486767</td>\n",
       "      <td>0.486546</td>\n",
       "      <td>0.486416</td>\n",
       "      <td>0.486643</td>\n",
       "      <td>0.487020</td>\n",
       "      <td>0.487260</td>\n",
       "      <td>...</td>\n",
       "      <td>0.517256</td>\n",
       "      <td>0.517579</td>\n",
       "      <td>0.515681</td>\n",
       "      <td>0.512732</td>\n",
       "      <td>0.509678</td>\n",
       "      <td>0.506267</td>\n",
       "      <td>0.502389</td>\n",
       "      <td>0.498500</td>\n",
       "      <td>0.494176</td>\n",
       "      <td>0.490107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75452 rows × 721 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ColumnName         0         1         2         3         4         5  \\\n",
       "144606          0  0.492344  0.491184  0.489745  0.487921  0.485960  0.483926   \n",
       "35913           0  0.434227  0.420098  0.409422  0.416141  0.412705  0.409911   \n",
       "167257          1  0.569916  0.565686  0.568726  0.559476  0.560414  0.561986   \n",
       "153815          1  0.510099  0.511281  0.512505  0.513753  0.514973  0.516206   \n",
       "163561          0  0.512019  0.512167  0.512318  0.512468  0.512607  0.512744   \n",
       "...           ...       ...       ...       ...       ...       ...       ...   \n",
       "204256          1  0.488184  0.482630  0.475795  0.469250  0.468647  0.470310   \n",
       "205101          1  0.509249  0.509337  0.509400  0.509459  0.509542  0.509615   \n",
       "141353          0  0.512035  0.515310  0.516407  0.516952  0.515331  0.512972   \n",
       "139862          0  0.473653  0.473915  0.474195  0.474498  0.474809  0.475130   \n",
       "212270          0  0.488235  0.487344  0.486847  0.486767  0.486546  0.486416   \n",
       "\n",
       "               6         7         8  ...       710       711       712  \\\n",
       "144606  0.481543  0.479170  0.477686  ...  0.476936  0.477933  0.479488   \n",
       "35913   0.415799  0.424124  0.424607  ...  0.514241  0.509941  0.512667   \n",
       "167257  0.558652  0.554033  0.552767  ...  0.512338  0.513878  0.511832   \n",
       "153815  0.517439  0.518695  0.520078  ...  0.499950  0.500905  0.501804   \n",
       "163561  0.512874  0.513004  0.513159  ...  0.510597  0.510765  0.510893   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "204256  0.473017  0.476345  0.477462  ...  0.499591  0.500172  0.499322   \n",
       "205101  0.509704  0.509772  0.509697  ...  0.508193  0.508274  0.508448   \n",
       "141353  0.509823  0.506638  0.506042  ...  0.485838  0.485401  0.479142   \n",
       "139862  0.475468  0.475811  0.476132  ...  0.472542  0.472606  0.472683   \n",
       "212270  0.486643  0.487020  0.487260  ...  0.517256  0.517579  0.515681   \n",
       "\n",
       "             713       714       715       716       717       718       719  \n",
       "144606  0.481302  0.482871  0.484442  0.486517  0.488512  0.490699  0.492546  \n",
       "35913   0.517600  0.516781  0.513453  0.517247  0.516293  0.512578  0.517158  \n",
       "167257  0.508585  0.509804  0.513054  0.508800  0.507294  0.511190  0.507380  \n",
       "153815  0.502709  0.503645  0.504611  0.505641  0.506713  0.507812  0.508941  \n",
       "163561  0.511012  0.511133  0.511256  0.511401  0.511554  0.511710  0.511868  \n",
       "...          ...       ...       ...       ...       ...       ...       ...  \n",
       "204256  0.497942  0.495688  0.493248  0.492444  0.491773  0.492283  0.492536  \n",
       "205101  0.508634  0.508814  0.508979  0.509066  0.509122  0.509155  0.509177  \n",
       "141353  0.473306  0.487065  0.505589  0.518955  0.530188  0.523752  0.511607  \n",
       "139862  0.472769  0.472875  0.472991  0.473090  0.473197  0.473306  0.473435  \n",
       "212270  0.512732  0.509678  0.506267  0.502389  0.498500  0.494176  0.490107  \n",
       "\n",
       "[75452 rows x 721 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced_under"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_balanced_under.iloc[:, 1:]  \n",
    "y = df_balanced_under.iloc[:, 0] \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "print(y_train.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.astype(int)\n",
    "y_test = y_test.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n",
      "2024-03-13 22:27:11.263716: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M3 Pro\n",
      "2024-03-13 22:27:11.263736: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 18.00 GB\n",
      "2024-03-13 22:27:11.263741: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 6.00 GB\n",
      "2024-03-13 22:27:11.263775: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-03-13 22:27:11.263786: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, BatchNormalization, MaxPooling1D, Dropout, Flatten, Dense\n",
    "from keras.optimizers import Adam, Adadelta\n",
    "\n",
    "Model = Sequential()\n",
    "\n",
    "Model.add(Conv1D(512, 10, strides=1, padding=\"same\", activation=\"relu\", input_shape=(720, 1)))\n",
    "Model.add(BatchNormalization())\n",
    "Model.add(MaxPooling1D(3, strides=2, padding=\"same\"))\n",
    "\n",
    "Model.add(Conv1D(256, 10, strides=1, padding=\"same\", activation=\"relu\"))\n",
    "Model.add(Dropout(0.2))\n",
    "Model.add(MaxPooling1D(3, strides=2, padding=\"same\"))\n",
    "\n",
    "Model.add(Conv1D(128, 10, strides=1, padding=\"same\", activation=\"relu\"))\n",
    "Model.add(Dropout(0.2))\n",
    "Model.add(MaxPooling1D(3, strides=2, padding=\"same\"))\n",
    "\n",
    "Model.add(Conv1D(64, 10, strides=1, padding=\"same\", activation=\"relu\"))\n",
    "Model.add(Dropout(0.2))\n",
    "Model.add(MaxPooling1D(3, strides=2, padding=\"same\"))\n",
    "\n",
    "Model.add(Conv1D(32, 10, strides=1, padding=\"same\", activation=\"relu\"))\n",
    "Model.add(Dropout(0.2))\n",
    "Model.add(MaxPooling1D(3, strides=2, padding=\"same\"))\n",
    "\n",
    "Model.add(Flatten())\n",
    "Model.add(Dense(1024, activation='relu'))\n",
    "Model.add(Dropout(0.2))\n",
    "\n",
    "Model.add(Dense(512, activation='relu'))\n",
    "Model.add(Dropout(0.2))\n",
    "\n",
    "Model.add(Dense(64, activation='relu'))\n",
    "Model.add(Dropout(0.2))\n",
    "\n",
    "Model.add(Dense(units=1, activation='sigmoid'))  # Use 'sigmoid' for binary classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">720</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,632</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">720</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">360</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">360</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,310,976</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">360</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">180</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">180</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">327,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">180</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">81,984</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">736</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">754,688</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">524,800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,832</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m720\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │         \u001b[38;5;34m5,632\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m720\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m360\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m360\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │     \u001b[38;5;34m1,310,976\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m360\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m180\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m180\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │       \u001b[38;5;34m327,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m180\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_2 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m90\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m90\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m81,984\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m90\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_3 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m45\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_4 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m45\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │        \u001b[38;5;34m20,512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m45\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_4 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m736\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │       \u001b[38;5;34m754,688\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m524,800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m32,832\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,061,345</span> (11.68 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,061,345\u001b[0m (11.68 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,060,321</span> (11.67 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,060,321\u001b[0m (11.67 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> (4.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,024\u001b[0m (4.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(Model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks\n",
    "Early_Stopper = tf.keras.callbacks.EarlyStopping(monitor=\"loss\", patience=3, mode=\"min\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "Model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-13 22:27:12.278508: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1887/1887\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 111ms/step - accuracy: 0.7565 - loss: 0.4939 - val_accuracy: 0.7041 - val_loss: 0.5624\n",
      "Epoch 2/70\n",
      "\u001b[1m1887/1887\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 112ms/step - accuracy: 0.8573 - loss: 0.3414 - val_accuracy: 0.8744 - val_loss: 0.3135\n",
      "Epoch 3/70\n",
      "\u001b[1m1887/1887\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 112ms/step - accuracy: 0.8723 - loss: 0.3052 - val_accuracy: 0.8784 - val_loss: 0.2976\n",
      "Epoch 4/70\n",
      "\u001b[1m1887/1887\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 112ms/step - accuracy: 0.8806 - loss: 0.2902 - val_accuracy: 0.8458 - val_loss: 0.3537\n",
      "Epoch 5/70\n",
      "\u001b[1m1887/1887\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 112ms/step - accuracy: 0.8865 - loss: 0.2753 - val_accuracy: 0.8596 - val_loss: 0.3456\n",
      "Epoch 6/70\n",
      "\u001b[1m1887/1887\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 113ms/step - accuracy: 0.8900 - loss: 0.2683 - val_accuracy: 0.8822 - val_loss: 0.2844\n",
      "Epoch 7/70\n",
      "\u001b[1m1887/1887\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 112ms/step - accuracy: 0.8934 - loss: 0.2576 - val_accuracy: 0.8842 - val_loss: 0.2866\n",
      "Epoch 8/70\n",
      "\u001b[1m1887/1887\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 113ms/step - accuracy: 0.8973 - loss: 0.2549 - val_accuracy: 0.8879 - val_loss: 0.2826\n",
      "Epoch 9/70\n",
      "\u001b[1m1887/1887\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 114ms/step - accuracy: 0.8998 - loss: 0.2399 - val_accuracy: 0.8949 - val_loss: 0.2640\n",
      "Epoch 10/70\n",
      "\u001b[1m1887/1887\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 114ms/step - accuracy: 0.8992 - loss: 0.2423 - val_accuracy: 0.8753 - val_loss: 0.3002\n",
      "Epoch 11/70\n",
      "\u001b[1m1887/1887\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 114ms/step - accuracy: 0.9031 - loss: 0.2352 - val_accuracy: 0.8865 - val_loss: 0.2652\n",
      "Epoch 12/70\n",
      "\u001b[1m1887/1887\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 114ms/step - accuracy: 0.9035 - loss: 0.2366 - val_accuracy: 0.8917 - val_loss: 0.2670\n",
      "Epoch 13/70\n",
      "\u001b[1m1887/1887\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 114ms/step - accuracy: 0.9085 - loss: 0.2253 - val_accuracy: 0.7992 - val_loss: 0.4815\n",
      "Epoch 14/70\n",
      "\u001b[1m1887/1887\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 114ms/step - accuracy: 0.9058 - loss: 0.2284 - val_accuracy: 0.8941 - val_loss: 0.2610\n",
      "Epoch 15/70\n",
      "\u001b[1m1887/1887\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 114ms/step - accuracy: 0.9106 - loss: 0.2246 - val_accuracy: 0.6947 - val_loss: 0.6054\n",
      "Epoch 16/70\n",
      "\u001b[1m1887/1887\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 116ms/step - accuracy: 0.9021 - loss: 0.2347 - val_accuracy: 0.8904 - val_loss: 0.2730\n",
      "Epoch 17/70\n",
      "\u001b[1m1887/1887\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 116ms/step - accuracy: 0.9104 - loss: 0.2171 - val_accuracy: 0.9037 - val_loss: 0.2409\n",
      "Epoch 18/70\n",
      "\u001b[1m1887/1887\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 115ms/step - accuracy: 0.9119 - loss: 0.2158 - val_accuracy: 0.9070 - val_loss: 0.2325\n",
      "Epoch 19/70\n",
      "\u001b[1m1887/1887\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 115ms/step - accuracy: 0.9115 - loss: 0.2150 - val_accuracy: 0.8930 - val_loss: 0.2624\n",
      "Epoch 20/70\n",
      "\u001b[1m1887/1887\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 114ms/step - accuracy: 0.9104 - loss: 0.2190 - val_accuracy: 0.8989 - val_loss: 0.2556\n",
      "Epoch 21/70\n",
      "\u001b[1m1887/1887\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 114ms/step - accuracy: 0.9089 - loss: 0.2209 - val_accuracy: 0.9086 - val_loss: 0.2310\n",
      "Epoch 22/70\n",
      "\u001b[1m1887/1887\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 115ms/step - accuracy: 0.9160 - loss: 0.2039 - val_accuracy: 0.9086 - val_loss: 0.2332\n",
      "Epoch 23/70\n",
      "\u001b[1m1887/1887\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 114ms/step - accuracy: 0.9153 - loss: 0.2064 - val_accuracy: 0.8824 - val_loss: 0.2933\n",
      "Epoch 24/70\n",
      "\u001b[1m1887/1887\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 114ms/step - accuracy: 0.9024 - loss: 0.2386 - val_accuracy: 0.9071 - val_loss: 0.2295\n",
      "Epoch 25/70\n",
      "\u001b[1m1887/1887\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 115ms/step - accuracy: 0.9141 - loss: 0.2109 - val_accuracy: 0.8908 - val_loss: 0.2635\n"
     ]
    }
   ],
   "source": [
    "Conv1D_Model = Model.fit(X_train, y_train, epochs=70, validation_data=(X_test, y_test), callbacks=[Early_Stopper])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "Model.save('Conv1D.h5')  # Saves the model to a HDF5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.8910 - loss: 0.2661\n",
      "LOSS:  0.2635\n",
      "ACCURACY:  0.8908\n"
     ]
    }
   ],
   "source": [
    "Model_Results = Model.evaluate(X_test,y_test)\n",
    "print(\"LOSS:  \" + \"%.4f\" % Model_Results[0])\n",
    "print(\"ACCURACY:  \" + \"%.4f\" % Model_Results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step\n"
     ]
    }
   ],
   "source": [
    "# Assuming your model is named 'Model'\n",
    "y_pred_probs = Model.predict(X_test)\n",
    "y_pred = (y_pred_probs > 0.5).astype(\"int32\")  # Convert probabilities to binary labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[6662  867]\n",
      " [ 781 6781]]\n",
      "Precision: 0.89\n",
      "Recall: 0.90\n",
      "F1 Score: 0.89\n",
      "ROC AUC Score: 0.96\n",
      "Log Loss: 0.26\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score, roc_curve, log_loss\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "# Precision\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "\n",
    "# Recall\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "\n",
    "# F1 Score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "\n",
    "# ROC-AUC Score\n",
    "roc_auc = roc_auc_score(y_test, y_pred_probs)\n",
    "print(f\"ROC AUC Score: {roc_auc:.2f}\")\n",
    "\n",
    "# Now, you can calculate the log loss\n",
    "logloss = log_loss(y_test, y_pred_probs)\n",
    "print(f\"Log Loss: {logloss:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-metal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
