{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fusionné = pd.read_csv('df_fusionné.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fusionné_binaire = df_fusionné.sample(frac=1)\n",
    "df_fusionné_binaire.iloc[:, 0] = df_fusionné_binaire.iloc[:, 0].apply(lambda x: 0 if x == 'N' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fusionné_binaire.to_csv('df_fusionné.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = df_fusionné_binaire.iloc[:, 0].value_counts()\n",
    "min_count = counts.min()\n",
    "\n",
    "# Create balanced DataFrame through undersampling\n",
    "df_balanced_under = pd.concat([\n",
    "    df_fusionné_binaire[df_fusionné_binaire.iloc[:, 0] == 0].sample(min_count),\n",
    "    df_fusionné_binaire[df_fusionné_binaire.iloc[:, 0] == 1].sample(min_count)\n",
    "])\n",
    "\n",
    "# Shuffle the DataFrame to mix the classes\n",
    "df_balanced_under = df_balanced_under.sample(frac=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ColumnName\n",
      "0    37726\n",
      "1    37726\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "value_counts = df_balanced_under.iloc[:, 0].value_counts()\n",
    "\n",
    "print(value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ColumnName</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>350</th>\n",
       "      <th>351</th>\n",
       "      <th>352</th>\n",
       "      <th>353</th>\n",
       "      <th>354</th>\n",
       "      <th>355</th>\n",
       "      <th>356</th>\n",
       "      <th>357</th>\n",
       "      <th>358</th>\n",
       "      <th>359</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45377</th>\n",
       "      <td>0</td>\n",
       "      <td>0.509339</td>\n",
       "      <td>0.509530</td>\n",
       "      <td>0.512644</td>\n",
       "      <td>0.503791</td>\n",
       "      <td>0.506233</td>\n",
       "      <td>0.509407</td>\n",
       "      <td>0.509099</td>\n",
       "      <td>0.507331</td>\n",
       "      <td>0.504404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.499443</td>\n",
       "      <td>0.499481</td>\n",
       "      <td>0.498744</td>\n",
       "      <td>0.497407</td>\n",
       "      <td>0.498676</td>\n",
       "      <td>0.499585</td>\n",
       "      <td>0.496168</td>\n",
       "      <td>0.495675</td>\n",
       "      <td>0.479093</td>\n",
       "      <td>0.449746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96628</th>\n",
       "      <td>1</td>\n",
       "      <td>0.483411</td>\n",
       "      <td>0.485394</td>\n",
       "      <td>0.487179</td>\n",
       "      <td>0.489062</td>\n",
       "      <td>0.491508</td>\n",
       "      <td>0.493937</td>\n",
       "      <td>0.496727</td>\n",
       "      <td>0.499262</td>\n",
       "      <td>0.499614</td>\n",
       "      <td>...</td>\n",
       "      <td>0.474541</td>\n",
       "      <td>0.475213</td>\n",
       "      <td>0.476169</td>\n",
       "      <td>0.477179</td>\n",
       "      <td>0.478344</td>\n",
       "      <td>0.479517</td>\n",
       "      <td>0.480193</td>\n",
       "      <td>0.480794</td>\n",
       "      <td>0.481286</td>\n",
       "      <td>0.481869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188789</th>\n",
       "      <td>0</td>\n",
       "      <td>0.471477</td>\n",
       "      <td>0.472859</td>\n",
       "      <td>0.473830</td>\n",
       "      <td>0.474277</td>\n",
       "      <td>0.474453</td>\n",
       "      <td>0.474431</td>\n",
       "      <td>0.473927</td>\n",
       "      <td>0.473320</td>\n",
       "      <td>0.473542</td>\n",
       "      <td>...</td>\n",
       "      <td>0.419520</td>\n",
       "      <td>0.428086</td>\n",
       "      <td>0.434184</td>\n",
       "      <td>0.439378</td>\n",
       "      <td>0.443972</td>\n",
       "      <td>0.448207</td>\n",
       "      <td>0.453534</td>\n",
       "      <td>0.458845</td>\n",
       "      <td>0.464139</td>\n",
       "      <td>0.468959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165654</th>\n",
       "      <td>1</td>\n",
       "      <td>0.580823</td>\n",
       "      <td>0.576716</td>\n",
       "      <td>0.588154</td>\n",
       "      <td>0.579712</td>\n",
       "      <td>0.584762</td>\n",
       "      <td>0.589635</td>\n",
       "      <td>0.586378</td>\n",
       "      <td>0.580634</td>\n",
       "      <td>0.580449</td>\n",
       "      <td>...</td>\n",
       "      <td>0.478223</td>\n",
       "      <td>0.481352</td>\n",
       "      <td>0.477076</td>\n",
       "      <td>0.470621</td>\n",
       "      <td>0.471157</td>\n",
       "      <td>0.475207</td>\n",
       "      <td>0.469896</td>\n",
       "      <td>0.470454</td>\n",
       "      <td>0.478185</td>\n",
       "      <td>0.473043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58157</th>\n",
       "      <td>1</td>\n",
       "      <td>0.500941</td>\n",
       "      <td>0.501428</td>\n",
       "      <td>0.501950</td>\n",
       "      <td>0.502496</td>\n",
       "      <td>0.502993</td>\n",
       "      <td>0.503474</td>\n",
       "      <td>0.503963</td>\n",
       "      <td>0.504440</td>\n",
       "      <td>0.504908</td>\n",
       "      <td>...</td>\n",
       "      <td>0.498497</td>\n",
       "      <td>0.498758</td>\n",
       "      <td>0.498987</td>\n",
       "      <td>0.499202</td>\n",
       "      <td>0.499447</td>\n",
       "      <td>0.499696</td>\n",
       "      <td>0.499902</td>\n",
       "      <td>0.500118</td>\n",
       "      <td>0.500311</td>\n",
       "      <td>0.500533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157704</th>\n",
       "      <td>0</td>\n",
       "      <td>0.483354</td>\n",
       "      <td>0.485110</td>\n",
       "      <td>0.486609</td>\n",
       "      <td>0.487876</td>\n",
       "      <td>0.488472</td>\n",
       "      <td>0.488705</td>\n",
       "      <td>0.488692</td>\n",
       "      <td>0.488483</td>\n",
       "      <td>0.488282</td>\n",
       "      <td>...</td>\n",
       "      <td>0.435014</td>\n",
       "      <td>0.446730</td>\n",
       "      <td>0.453537</td>\n",
       "      <td>0.459017</td>\n",
       "      <td>0.466661</td>\n",
       "      <td>0.474099</td>\n",
       "      <td>0.477652</td>\n",
       "      <td>0.479634</td>\n",
       "      <td>0.480934</td>\n",
       "      <td>0.481678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21256</th>\n",
       "      <td>1</td>\n",
       "      <td>0.466148</td>\n",
       "      <td>0.466499</td>\n",
       "      <td>0.466846</td>\n",
       "      <td>0.467205</td>\n",
       "      <td>0.467584</td>\n",
       "      <td>0.467953</td>\n",
       "      <td>0.468337</td>\n",
       "      <td>0.468692</td>\n",
       "      <td>0.468898</td>\n",
       "      <td>...</td>\n",
       "      <td>0.464556</td>\n",
       "      <td>0.464550</td>\n",
       "      <td>0.464638</td>\n",
       "      <td>0.464771</td>\n",
       "      <td>0.464945</td>\n",
       "      <td>0.465145</td>\n",
       "      <td>0.465308</td>\n",
       "      <td>0.465479</td>\n",
       "      <td>0.465652</td>\n",
       "      <td>0.465846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170871</th>\n",
       "      <td>0</td>\n",
       "      <td>0.486213</td>\n",
       "      <td>0.487750</td>\n",
       "      <td>0.494365</td>\n",
       "      <td>0.488585</td>\n",
       "      <td>0.490531</td>\n",
       "      <td>0.492304</td>\n",
       "      <td>0.488633</td>\n",
       "      <td>0.483586</td>\n",
       "      <td>0.483794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.427793</td>\n",
       "      <td>0.430619</td>\n",
       "      <td>0.429053</td>\n",
       "      <td>0.426677</td>\n",
       "      <td>0.424545</td>\n",
       "      <td>0.422944</td>\n",
       "      <td>0.427832</td>\n",
       "      <td>0.439085</td>\n",
       "      <td>0.436982</td>\n",
       "      <td>0.422765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12085</th>\n",
       "      <td>1</td>\n",
       "      <td>0.487786</td>\n",
       "      <td>0.490419</td>\n",
       "      <td>0.487009</td>\n",
       "      <td>0.479385</td>\n",
       "      <td>0.486944</td>\n",
       "      <td>0.497983</td>\n",
       "      <td>0.493073</td>\n",
       "      <td>0.483983</td>\n",
       "      <td>0.484162</td>\n",
       "      <td>...</td>\n",
       "      <td>0.401654</td>\n",
       "      <td>0.379841</td>\n",
       "      <td>0.363237</td>\n",
       "      <td>0.347362</td>\n",
       "      <td>0.333555</td>\n",
       "      <td>0.324101</td>\n",
       "      <td>0.291626</td>\n",
       "      <td>0.272952</td>\n",
       "      <td>0.272448</td>\n",
       "      <td>0.243541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155267</th>\n",
       "      <td>0</td>\n",
       "      <td>0.399217</td>\n",
       "      <td>0.396279</td>\n",
       "      <td>0.384302</td>\n",
       "      <td>0.392570</td>\n",
       "      <td>0.385648</td>\n",
       "      <td>0.378624</td>\n",
       "      <td>0.379979</td>\n",
       "      <td>0.384202</td>\n",
       "      <td>0.384484</td>\n",
       "      <td>...</td>\n",
       "      <td>0.503549</td>\n",
       "      <td>0.498516</td>\n",
       "      <td>0.501092</td>\n",
       "      <td>0.506198</td>\n",
       "      <td>0.503839</td>\n",
       "      <td>0.498269</td>\n",
       "      <td>0.504123</td>\n",
       "      <td>0.504798</td>\n",
       "      <td>0.499278</td>\n",
       "      <td>0.505853</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75452 rows × 361 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ColumnName         0         1         2         3         4         5  \\\n",
       "45377           0  0.509339  0.509530  0.512644  0.503791  0.506233  0.509407   \n",
       "96628           1  0.483411  0.485394  0.487179  0.489062  0.491508  0.493937   \n",
       "188789          0  0.471477  0.472859  0.473830  0.474277  0.474453  0.474431   \n",
       "165654          1  0.580823  0.576716  0.588154  0.579712  0.584762  0.589635   \n",
       "58157           1  0.500941  0.501428  0.501950  0.502496  0.502993  0.503474   \n",
       "...           ...       ...       ...       ...       ...       ...       ...   \n",
       "157704          0  0.483354  0.485110  0.486609  0.487876  0.488472  0.488705   \n",
       "21256           1  0.466148  0.466499  0.466846  0.467205  0.467584  0.467953   \n",
       "170871          0  0.486213  0.487750  0.494365  0.488585  0.490531  0.492304   \n",
       "12085           1  0.487786  0.490419  0.487009  0.479385  0.486944  0.497983   \n",
       "155267          0  0.399217  0.396279  0.384302  0.392570  0.385648  0.378624   \n",
       "\n",
       "               6         7         8  ...       350       351       352  \\\n",
       "45377   0.509099  0.507331  0.504404  ...  0.499443  0.499481  0.498744   \n",
       "96628   0.496727  0.499262  0.499614  ...  0.474541  0.475213  0.476169   \n",
       "188789  0.473927  0.473320  0.473542  ...  0.419520  0.428086  0.434184   \n",
       "165654  0.586378  0.580634  0.580449  ...  0.478223  0.481352  0.477076   \n",
       "58157   0.503963  0.504440  0.504908  ...  0.498497  0.498758  0.498987   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "157704  0.488692  0.488483  0.488282  ...  0.435014  0.446730  0.453537   \n",
       "21256   0.468337  0.468692  0.468898  ...  0.464556  0.464550  0.464638   \n",
       "170871  0.488633  0.483586  0.483794  ...  0.427793  0.430619  0.429053   \n",
       "12085   0.493073  0.483983  0.484162  ...  0.401654  0.379841  0.363237   \n",
       "155267  0.379979  0.384202  0.384484  ...  0.503549  0.498516  0.501092   \n",
       "\n",
       "             353       354       355       356       357       358       359  \n",
       "45377   0.497407  0.498676  0.499585  0.496168  0.495675  0.479093  0.449746  \n",
       "96628   0.477179  0.478344  0.479517  0.480193  0.480794  0.481286  0.481869  \n",
       "188789  0.439378  0.443972  0.448207  0.453534  0.458845  0.464139  0.468959  \n",
       "165654  0.470621  0.471157  0.475207  0.469896  0.470454  0.478185  0.473043  \n",
       "58157   0.499202  0.499447  0.499696  0.499902  0.500118  0.500311  0.500533  \n",
       "...          ...       ...       ...       ...       ...       ...       ...  \n",
       "157704  0.459017  0.466661  0.474099  0.477652  0.479634  0.480934  0.481678  \n",
       "21256   0.464771  0.464945  0.465145  0.465308  0.465479  0.465652  0.465846  \n",
       "170871  0.426677  0.424545  0.422944  0.427832  0.439085  0.436982  0.422765  \n",
       "12085   0.347362  0.333555  0.324101  0.291626  0.272952  0.272448  0.243541  \n",
       "155267  0.506198  0.503839  0.498269  0.504123  0.504798  0.499278  0.505853  \n",
       "\n",
       "[75452 rows x 361 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced_under"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_balanced_under.iloc[:, 1:]  \n",
    "y = df_balanced_under.iloc[:, 0] \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_train.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.astype(int)\n",
    "y_test = y_test.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, BatchNormalization, MaxPooling1D, Dropout, Flatten, Dense\n",
    "from keras.optimizers import Adam, Adadelta\n",
    "\n",
    "Model = Sequential()\n",
    "\n",
    "Model.add(Conv1D(512, 10, strides=1, padding=\"same\", activation=\"relu\", input_shape=(360, 1)))\n",
    "Model.add(BatchNormalization())\n",
    "Model.add(MaxPooling1D(3, strides=2, padding=\"same\"))\n",
    "\n",
    "Model.add(Conv1D(256, 10, strides=1, padding=\"same\", activation=\"relu\"))\n",
    "Model.add(Dropout(0.2))\n",
    "Model.add(MaxPooling1D(3, strides=2, padding=\"same\"))\n",
    "\n",
    "Model.add(Conv1D(128, 10, strides=1, padding=\"same\", activation=\"relu\"))\n",
    "Model.add(Dropout(0.2))\n",
    "Model.add(MaxPooling1D(3, strides=2, padding=\"same\"))\n",
    "\n",
    "Model.add(Conv1D(64, 10, strides=1, padding=\"same\", activation=\"relu\"))\n",
    "Model.add(Dropout(0.2))\n",
    "Model.add(MaxPooling1D(3, strides=2, padding=\"same\"))\n",
    "\n",
    "Model.add(Conv1D(32, 10, strides=1, padding=\"same\", activation=\"relu\"))\n",
    "Model.add(Dropout(0.2))\n",
    "Model.add(MaxPooling1D(3, strides=2, padding=\"same\"))\n",
    "\n",
    "Model.add(Flatten())\n",
    "Model.add(Dense(1024, activation='relu'))\n",
    "Model.add(Dropout(0.2))\n",
    "\n",
    "Model.add(Dense(512, activation='relu'))\n",
    "Model.add(Dropout(0.2))\n",
    "\n",
    "Model.add(Dense(64, activation='relu'))\n",
    "Model.add(Dropout(0.2))\n",
    "\n",
    "Model.add(Dense(units=1, activation='sigmoid'))  # Use 'sigmoid' for binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">360</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,632</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">360</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">180</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">180</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,310,976</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">180</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">327,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">81,984</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">394,240</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">524,800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,832</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_5 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m360\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │         \u001b[38;5;34m5,632\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m360\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_5 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m180\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_6 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m180\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │     \u001b[38;5;34m1,310,976\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m180\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_6 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m90\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_7 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m90\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │       \u001b[38;5;34m327,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m90\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_7 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m45\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_8 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m45\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m81,984\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m45\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_8 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_9 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │        \u001b[38;5;34m20,512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_9 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m384\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │       \u001b[38;5;34m394,240\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_11 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m524,800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_12 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m32,832\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_13 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,700,897</span> (10.30 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,700,897\u001b[0m (10.30 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,699,873</span> (10.30 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,699,873\u001b[0m (10.30 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> (4.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,024\u001b[0m (4.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(Model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks\n",
    "Early_Stopper = tf.keras.callbacks.EarlyStopping(monitor=\"loss\", patience=3, mode=\"min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-01 21:18:52.558770: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1887/1887\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 80ms/step - accuracy: 0.7714 - loss: 0.4748 - val_accuracy: 0.6144 - val_loss: 0.6660\n",
      "Epoch 2/70\n",
      "\u001b[1m1887/1887\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 170ms/step - accuracy: 0.8723 - loss: 0.3155 - val_accuracy: 0.8258 - val_loss: 0.4174\n",
      "Epoch 3/70\n",
      "\u001b[1m1887/1887\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 90ms/step - accuracy: 0.8949 - loss: 0.2689 - val_accuracy: 0.8107 - val_loss: 0.4416\n",
      "Epoch 4/70\n",
      "\u001b[1m1887/1887\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 89ms/step - accuracy: 0.9041 - loss: 0.2473 - val_accuracy: 0.8508 - val_loss: 0.3636\n",
      "Epoch 5/70\n",
      "\u001b[1m1887/1887\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 89ms/step - accuracy: 0.9128 - loss: 0.2309 - val_accuracy: 0.8412 - val_loss: 0.3857\n",
      "Epoch 6/70\n",
      "\u001b[1m1887/1887\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 89ms/step - accuracy: 0.9152 - loss: 0.2265 - val_accuracy: 0.9005 - val_loss: 0.2697\n",
      "Epoch 7/70\n",
      "\u001b[1m1887/1887\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 89ms/step - accuracy: 0.9168 - loss: 0.2215 - val_accuracy: 0.7909 - val_loss: 0.4516\n",
      "Epoch 8/70\n",
      "\u001b[1m1887/1887\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 89ms/step - accuracy: 0.9212 - loss: 0.2096 - val_accuracy: 0.9166 - val_loss: 0.2318\n",
      "Epoch 9/70\n",
      "\u001b[1m1887/1887\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 89ms/step - accuracy: 0.9244 - loss: 0.2023 - val_accuracy: 0.8430 - val_loss: 0.3773\n",
      "Epoch 10/70\n",
      "\u001b[1m1887/1887\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 89ms/step - accuracy: 0.9259 - loss: 0.2019 - val_accuracy: 0.8506 - val_loss: 0.3465\n",
      "Epoch 11/70\n",
      "\u001b[1m1887/1887\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 90ms/step - accuracy: 0.9252 - loss: 0.1957 - val_accuracy: 0.9315 - val_loss: 0.1851\n",
      "Epoch 12/70\n",
      "\u001b[1m1887/1887\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 89ms/step - accuracy: 0.9279 - loss: 0.1978 - val_accuracy: 0.9227 - val_loss: 0.2116\n",
      "Epoch 13/70\n",
      "\u001b[1m1887/1887\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 89ms/step - accuracy: 0.9315 - loss: 0.1851 - val_accuracy: 0.9268 - val_loss: 0.2167\n",
      "Epoch 14/70\n",
      "\u001b[1m1887/1887\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 90ms/step - accuracy: 0.9322 - loss: 0.1833 - val_accuracy: 0.8883 - val_loss: 0.2961\n",
      "Epoch 15/70\n",
      "\u001b[1m1887/1887\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 90ms/step - accuracy: 0.9324 - loss: 0.1829 - val_accuracy: 0.9274 - val_loss: 0.1958\n",
      "Epoch 16/70\n",
      "\u001b[1m1887/1887\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 90ms/step - accuracy: 0.9326 - loss: 0.1847 - val_accuracy: 0.9171 - val_loss: 0.2181\n",
      "Epoch 17/70\n",
      "\u001b[1m1887/1887\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 90ms/step - accuracy: 0.9357 - loss: 0.1764 - val_accuracy: 0.8812 - val_loss: 0.2967\n",
      "Epoch 18/70\n",
      "\u001b[1m1887/1887\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 91ms/step - accuracy: 0.9350 - loss: 0.1786 - val_accuracy: 0.9226 - val_loss: 0.2234\n",
      "Epoch 19/70\n",
      "\u001b[1m1887/1887\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 91ms/step - accuracy: 0.9318 - loss: 0.1842 - val_accuracy: 0.9285 - val_loss: 0.2038\n",
      "Epoch 20/70\n",
      "\u001b[1m1887/1887\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 90ms/step - accuracy: 0.9345 - loss: 0.1748 - val_accuracy: 0.8600 - val_loss: 0.3311\n",
      "Epoch 21/70\n",
      "\u001b[1m1887/1887\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 90ms/step - accuracy: 0.9358 - loss: 0.1745 - val_accuracy: 0.9224 - val_loss: 0.2072\n",
      "Epoch 22/70\n",
      "\u001b[1m1887/1887\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 91ms/step - accuracy: 0.9377 - loss: 0.1690 - val_accuracy: 0.8697 - val_loss: 0.3315\n",
      "Epoch 23/70\n",
      "\u001b[1m1887/1887\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 89ms/step - accuracy: 0.9376 - loss: 0.1725 - val_accuracy: 0.8936 - val_loss: 0.3192\n",
      "Epoch 24/70\n",
      "\u001b[1m1887/1887\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 90ms/step - accuracy: 0.9368 - loss: 0.1714 - val_accuracy: 0.9205 - val_loss: 0.2427\n",
      "Epoch 25/70\n",
      "\u001b[1m1887/1887\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 91ms/step - accuracy: 0.9333 - loss: 0.1778 - val_accuracy: 0.9363 - val_loss: 0.1862\n",
      "Epoch 26/70\n",
      "\u001b[1m1887/1887\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 92ms/step - accuracy: 0.9381 - loss: 0.1673 - val_accuracy: 0.9240 - val_loss: 0.2176\n",
      "Epoch 27/70\n",
      "\u001b[1m1887/1887\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 92ms/step - accuracy: 0.9349 - loss: 0.1734 - val_accuracy: 0.9253 - val_loss: 0.2125\n",
      "Epoch 28/70\n",
      "\u001b[1m1887/1887\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 92ms/step - accuracy: 0.9376 - loss: 0.1709 - val_accuracy: 0.9321 - val_loss: 0.1860\n",
      "Epoch 29/70\n",
      "\u001b[1m1887/1887\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 91ms/step - accuracy: 0.9343 - loss: 0.1827 - val_accuracy: 0.9210 - val_loss: 0.2071\n"
     ]
    }
   ],
   "source": [
    "Conv1D_Model = Model.fit(X_train, y_train, epochs=70, validation_data=(X_test, y_test), callbacks=[Early_Stopper])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "Model.save('Conv1D.h5')  # Saves the model to a HDF5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.9197 - loss: 0.2064\n",
      "LOSS:  0.2071\n",
      "ACCURACY:  0.9210\n"
     ]
    }
   ],
   "source": [
    "Model_Results = Model.evaluate(X_test,y_test)\n",
    "print(\"LOSS:  \" + \"%.4f\" % Model_Results[0])\n",
    "print(\"ACCURACY:  \" + \"%.4f\" % Model_Results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step\n"
     ]
    }
   ],
   "source": [
    "# Assuming your model is named 'Model'\n",
    "y_pred_probs = Model.predict(X_test)\n",
    "y_pred = (y_pred_probs > 0.5).astype(\"int32\")  # Convert probabilities to binary labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[6969  525]\n",
      " [ 667 6930]]\n",
      "Precision: 0.93\n",
      "Recall: 0.91\n",
      "F1 Score: 0.92\n",
      "ROC AUC Score: 0.98\n",
      "Log Loss: 0.21\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score, roc_curve, log_loss\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "# Precision\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "\n",
    "# Recall\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "\n",
    "# F1 Score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "\n",
    "# ROC-AUC Score\n",
    "roc_auc = roc_auc_score(y_test, y_pred_probs)\n",
    "print(f\"ROC AUC Score: {roc_auc:.2f}\")\n",
    "\n",
    "# Now, you can calculate the log loss\n",
    "logloss = log_loss(y_test, y_pred_probs)\n",
    "print(f\"Log Loss: {logloss:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1812788359.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[28], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    Confusion Matrix:\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Confusion Matrix:\n",
    " [[705  42]\n",
    " [134 606]]\n",
    "Precision: 0.94\n",
    "Recall: 0.82\n",
    "F1 Score: 0.87\n",
    "ROC AUC Score: 0.96\n",
    "Log Loss: 0.30"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-metal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
