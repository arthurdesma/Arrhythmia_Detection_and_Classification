{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fusionné = pd.read_csv('df_fusionné.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fusionné = df_fusionné.sample(frac=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anormal = df_fusionné[df_fusionné[\"ColumnName\"] != \"N\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ColumnName\n",
      "Q    16086\n",
      "V    14472\n",
      "S     5562\n",
      "F     1606\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "value_counts = df_anormal[\"ColumnName\"].value_counts()\n",
    "print(value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New class counts:\n",
      "ColumnName\n",
      "S    1606\n",
      "V    1606\n",
      "Q    1606\n",
      "F    1606\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Assuming df_anormal is your DataFrame and 'ColumnName' is the column with class labels\n",
    "# The target size is the smallest class count, which is 1606 for class 'F'\n",
    "target_size = 1606\n",
    "\n",
    "# Sample each class in the DataFrame to have the same number of samples as the smallest class\n",
    "balanced_df = pd.DataFrame()  # This will be the new DataFrame with balanced classes\n",
    "\n",
    "for label in df_anormal['ColumnName'].unique():\n",
    "    df_subset = df_anormal[df_anormal['ColumnName'] == label]\n",
    "    balanced_subset = df_subset.sample(n=target_size, random_state=42)  # Use a fixed seed for reproducibility\n",
    "    balanced_df = pd.concat([balanced_df, balanced_subset])\n",
    "\n",
    "# Reset index of the new DataFrame\n",
    "balanced_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(\"New class counts:\")\n",
    "print(balanced_df['ColumnName'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ColumnName</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>1430</th>\n",
       "      <th>1431</th>\n",
       "      <th>1432</th>\n",
       "      <th>1433</th>\n",
       "      <th>1434</th>\n",
       "      <th>1435</th>\n",
       "      <th>1436</th>\n",
       "      <th>1437</th>\n",
       "      <th>1438</th>\n",
       "      <th>1439</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S</td>\n",
       "      <td>0.498203</td>\n",
       "      <td>0.499715</td>\n",
       "      <td>0.501397</td>\n",
       "      <td>0.503192</td>\n",
       "      <td>0.504812</td>\n",
       "      <td>0.506426</td>\n",
       "      <td>0.508057</td>\n",
       "      <td>0.509718</td>\n",
       "      <td>0.511629</td>\n",
       "      <td>...</td>\n",
       "      <td>0.491440</td>\n",
       "      <td>0.492323</td>\n",
       "      <td>0.492928</td>\n",
       "      <td>0.493435</td>\n",
       "      <td>0.494023</td>\n",
       "      <td>0.494621</td>\n",
       "      <td>0.495158</td>\n",
       "      <td>0.495754</td>\n",
       "      <td>0.496299</td>\n",
       "      <td>0.496956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S</td>\n",
       "      <td>0.509112</td>\n",
       "      <td>0.509554</td>\n",
       "      <td>0.509776</td>\n",
       "      <td>0.509790</td>\n",
       "      <td>0.509856</td>\n",
       "      <td>0.509863</td>\n",
       "      <td>0.509730</td>\n",
       "      <td>0.509524</td>\n",
       "      <td>0.509289</td>\n",
       "      <td>...</td>\n",
       "      <td>0.490387</td>\n",
       "      <td>0.493197</td>\n",
       "      <td>0.495310</td>\n",
       "      <td>0.497184</td>\n",
       "      <td>0.498866</td>\n",
       "      <td>0.500450</td>\n",
       "      <td>0.502430</td>\n",
       "      <td>0.504401</td>\n",
       "      <td>0.506403</td>\n",
       "      <td>0.508225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S</td>\n",
       "      <td>0.477176</td>\n",
       "      <td>0.477812</td>\n",
       "      <td>0.478485</td>\n",
       "      <td>0.479221</td>\n",
       "      <td>0.480026</td>\n",
       "      <td>0.480862</td>\n",
       "      <td>0.481766</td>\n",
       "      <td>0.482679</td>\n",
       "      <td>0.483423</td>\n",
       "      <td>...</td>\n",
       "      <td>0.475006</td>\n",
       "      <td>0.475204</td>\n",
       "      <td>0.475368</td>\n",
       "      <td>0.475521</td>\n",
       "      <td>0.475720</td>\n",
       "      <td>0.475935</td>\n",
       "      <td>0.476093</td>\n",
       "      <td>0.476274</td>\n",
       "      <td>0.476447</td>\n",
       "      <td>0.476677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S</td>\n",
       "      <td>0.519417</td>\n",
       "      <td>0.523367</td>\n",
       "      <td>0.528685</td>\n",
       "      <td>0.533486</td>\n",
       "      <td>0.531742</td>\n",
       "      <td>0.527716</td>\n",
       "      <td>0.522264</td>\n",
       "      <td>0.516466</td>\n",
       "      <td>0.515130</td>\n",
       "      <td>...</td>\n",
       "      <td>0.503931</td>\n",
       "      <td>0.503267</td>\n",
       "      <td>0.504432</td>\n",
       "      <td>0.506327</td>\n",
       "      <td>0.508881</td>\n",
       "      <td>0.511642</td>\n",
       "      <td>0.513296</td>\n",
       "      <td>0.514818</td>\n",
       "      <td>0.515341</td>\n",
       "      <td>0.515902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S</td>\n",
       "      <td>0.508610</td>\n",
       "      <td>0.508441</td>\n",
       "      <td>0.508229</td>\n",
       "      <td>0.507993</td>\n",
       "      <td>0.507802</td>\n",
       "      <td>0.507606</td>\n",
       "      <td>0.507409</td>\n",
       "      <td>0.507194</td>\n",
       "      <td>0.506871</td>\n",
       "      <td>...</td>\n",
       "      <td>0.508809</td>\n",
       "      <td>0.508763</td>\n",
       "      <td>0.508760</td>\n",
       "      <td>0.508771</td>\n",
       "      <td>0.508771</td>\n",
       "      <td>0.508767</td>\n",
       "      <td>0.508770</td>\n",
       "      <td>0.508761</td>\n",
       "      <td>0.508759</td>\n",
       "      <td>0.508734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6419</th>\n",
       "      <td>F</td>\n",
       "      <td>0.470792</td>\n",
       "      <td>0.474672</td>\n",
       "      <td>0.464490</td>\n",
       "      <td>0.476011</td>\n",
       "      <td>0.471428</td>\n",
       "      <td>0.466360</td>\n",
       "      <td>0.470277</td>\n",
       "      <td>0.476566</td>\n",
       "      <td>0.475796</td>\n",
       "      <td>...</td>\n",
       "      <td>0.585012</td>\n",
       "      <td>0.580923</td>\n",
       "      <td>0.585440</td>\n",
       "      <td>0.592865</td>\n",
       "      <td>0.592314</td>\n",
       "      <td>0.587616</td>\n",
       "      <td>0.595581</td>\n",
       "      <td>0.597872</td>\n",
       "      <td>0.585737</td>\n",
       "      <td>0.585435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6420</th>\n",
       "      <td>F</td>\n",
       "      <td>0.472230</td>\n",
       "      <td>0.483557</td>\n",
       "      <td>0.478036</td>\n",
       "      <td>0.467935</td>\n",
       "      <td>0.467892</td>\n",
       "      <td>0.470304</td>\n",
       "      <td>0.470565</td>\n",
       "      <td>0.470559</td>\n",
       "      <td>0.470530</td>\n",
       "      <td>...</td>\n",
       "      <td>0.456231</td>\n",
       "      <td>0.455535</td>\n",
       "      <td>0.456373</td>\n",
       "      <td>0.457901</td>\n",
       "      <td>0.460120</td>\n",
       "      <td>0.462486</td>\n",
       "      <td>0.464579</td>\n",
       "      <td>0.467114</td>\n",
       "      <td>0.466050</td>\n",
       "      <td>0.463491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6421</th>\n",
       "      <td>F</td>\n",
       "      <td>0.519919</td>\n",
       "      <td>0.517292</td>\n",
       "      <td>0.514850</td>\n",
       "      <td>0.512352</td>\n",
       "      <td>0.509429</td>\n",
       "      <td>0.506582</td>\n",
       "      <td>0.503527</td>\n",
       "      <td>0.500776</td>\n",
       "      <td>0.499948</td>\n",
       "      <td>...</td>\n",
       "      <td>0.535902</td>\n",
       "      <td>0.533823</td>\n",
       "      <td>0.532150</td>\n",
       "      <td>0.530639</td>\n",
       "      <td>0.528992</td>\n",
       "      <td>0.527366</td>\n",
       "      <td>0.526015</td>\n",
       "      <td>0.524669</td>\n",
       "      <td>0.523452</td>\n",
       "      <td>0.522144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6422</th>\n",
       "      <td>F</td>\n",
       "      <td>0.489571</td>\n",
       "      <td>0.491727</td>\n",
       "      <td>0.494136</td>\n",
       "      <td>0.496677</td>\n",
       "      <td>0.499145</td>\n",
       "      <td>0.501713</td>\n",
       "      <td>0.504294</td>\n",
       "      <td>0.507008</td>\n",
       "      <td>0.510383</td>\n",
       "      <td>...</td>\n",
       "      <td>0.481971</td>\n",
       "      <td>0.479574</td>\n",
       "      <td>0.478877</td>\n",
       "      <td>0.479059</td>\n",
       "      <td>0.479683</td>\n",
       "      <td>0.480777</td>\n",
       "      <td>0.482036</td>\n",
       "      <td>0.483541</td>\n",
       "      <td>0.485404</td>\n",
       "      <td>0.487500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6423</th>\n",
       "      <td>F</td>\n",
       "      <td>0.464644</td>\n",
       "      <td>0.468500</td>\n",
       "      <td>0.473675</td>\n",
       "      <td>0.478454</td>\n",
       "      <td>0.477684</td>\n",
       "      <td>0.475118</td>\n",
       "      <td>0.471298</td>\n",
       "      <td>0.467357</td>\n",
       "      <td>0.468147</td>\n",
       "      <td>...</td>\n",
       "      <td>0.447722</td>\n",
       "      <td>0.447966</td>\n",
       "      <td>0.448567</td>\n",
       "      <td>0.449589</td>\n",
       "      <td>0.451243</td>\n",
       "      <td>0.453233</td>\n",
       "      <td>0.455219</td>\n",
       "      <td>0.457459</td>\n",
       "      <td>0.459137</td>\n",
       "      <td>0.460963</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6424 rows × 1441 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ColumnName         0         1         2         3         4         5  \\\n",
       "0             S  0.498203  0.499715  0.501397  0.503192  0.504812  0.506426   \n",
       "1             S  0.509112  0.509554  0.509776  0.509790  0.509856  0.509863   \n",
       "2             S  0.477176  0.477812  0.478485  0.479221  0.480026  0.480862   \n",
       "3             S  0.519417  0.523367  0.528685  0.533486  0.531742  0.527716   \n",
       "4             S  0.508610  0.508441  0.508229  0.507993  0.507802  0.507606   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "6419          F  0.470792  0.474672  0.464490  0.476011  0.471428  0.466360   \n",
       "6420          F  0.472230  0.483557  0.478036  0.467935  0.467892  0.470304   \n",
       "6421          F  0.519919  0.517292  0.514850  0.512352  0.509429  0.506582   \n",
       "6422          F  0.489571  0.491727  0.494136  0.496677  0.499145  0.501713   \n",
       "6423          F  0.464644  0.468500  0.473675  0.478454  0.477684  0.475118   \n",
       "\n",
       "             6         7         8  ...      1430      1431      1432  \\\n",
       "0     0.508057  0.509718  0.511629  ...  0.491440  0.492323  0.492928   \n",
       "1     0.509730  0.509524  0.509289  ...  0.490387  0.493197  0.495310   \n",
       "2     0.481766  0.482679  0.483423  ...  0.475006  0.475204  0.475368   \n",
       "3     0.522264  0.516466  0.515130  ...  0.503931  0.503267  0.504432   \n",
       "4     0.507409  0.507194  0.506871  ...  0.508809  0.508763  0.508760   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "6419  0.470277  0.476566  0.475796  ...  0.585012  0.580923  0.585440   \n",
       "6420  0.470565  0.470559  0.470530  ...  0.456231  0.455535  0.456373   \n",
       "6421  0.503527  0.500776  0.499948  ...  0.535902  0.533823  0.532150   \n",
       "6422  0.504294  0.507008  0.510383  ...  0.481971  0.479574  0.478877   \n",
       "6423  0.471298  0.467357  0.468147  ...  0.447722  0.447966  0.448567   \n",
       "\n",
       "          1433      1434      1435      1436      1437      1438      1439  \n",
       "0     0.493435  0.494023  0.494621  0.495158  0.495754  0.496299  0.496956  \n",
       "1     0.497184  0.498866  0.500450  0.502430  0.504401  0.506403  0.508225  \n",
       "2     0.475521  0.475720  0.475935  0.476093  0.476274  0.476447  0.476677  \n",
       "3     0.506327  0.508881  0.511642  0.513296  0.514818  0.515341  0.515902  \n",
       "4     0.508771  0.508771  0.508767  0.508770  0.508761  0.508759  0.508734  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "6419  0.592865  0.592314  0.587616  0.595581  0.597872  0.585737  0.585435  \n",
       "6420  0.457901  0.460120  0.462486  0.464579  0.467114  0.466050  0.463491  \n",
       "6421  0.530639  0.528992  0.527366  0.526015  0.524669  0.523452  0.522144  \n",
       "6422  0.479059  0.479683  0.480777  0.482036  0.483541  0.485404  0.487500  \n",
       "6423  0.449589  0.451243  0.453233  0.455219  0.457459  0.459137  0.460963  \n",
       "\n",
       "[6424 rows x 1441 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_anormal.iloc[:, 1:]\n",
    "y = df_anormal.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "y_categorical = to_categorical(y_encoded)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_categorical, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2160"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_15 (Conv1D)          (None, 2155, 64)          448       \n",
      "                                                                 \n",
      " max_pooling1d_15 (MaxPooli  (None, 718, 64)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " batch_normalization_15 (Ba  (None, 718, 64)           256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv1d_16 (Conv1D)          (None, 713, 128)          49280     \n",
      "                                                                 \n",
      " max_pooling1d_16 (MaxPooli  (None, 356, 128)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " batch_normalization_16 (Ba  (None, 356, 128)          512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv1d_17 (Conv1D)          (None, 351, 128)          98432     \n",
      "                                                                 \n",
      " max_pooling1d_17 (MaxPooli  (None, 175, 128)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " batch_normalization_17 (Ba  (None, 175, 128)          512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv1d_18 (Conv1D)          (None, 170, 64)           49216     \n",
      "                                                                 \n",
      " max_pooling1d_18 (MaxPooli  (None, 85, 64)            0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " batch_normalization_18 (Ba  (None, 85, 64)            256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 5440)              0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 64)                348224    \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 4)                 132       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 549348 (2.10 MB)\n",
      "Trainable params: 548580 (2.09 MB)\n",
      "Non-trainable params: 768 (3.00 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Conv1D(filters=64, kernel_size=6, activation='relu', input_shape=(X_train.shape[1], 1)),\n",
    "    MaxPooling1D(pool_size=3),\n",
    "    BatchNormalization(),\n",
    "\n",
    "    Conv1D(filters=128, kernel_size=6, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    BatchNormalization(),\n",
    "\n",
    "    Conv1D(filters=128, kernel_size=6, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    BatchNormalization(),\n",
    "\n",
    "    Conv1D(filters=64, kernel_size=6, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    BatchNormalization(),\n",
    "\n",
    "    Flatten(),\n",
    "\n",
    "    Dense(64, activation='relu'),\n",
    "\n",
    "    Dense(32, activation='relu'),\n",
    "\n",
    "    Dense(4, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['f1'])\n",
    "\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "354/354 [==============================] - 14s 36ms/step - loss: 0.4498 - accuracy: 0.9100 - val_loss: 0.7126 - val_accuracy: 0.8031\n",
      "Epoch 2/10\n",
      "354/354 [==============================] - 12s 34ms/step - loss: 0.3175 - accuracy: 0.9443 - val_loss: 0.2777 - val_accuracy: 0.9465\n",
      "Epoch 3/10\n",
      "354/354 [==============================] - 12s 34ms/step - loss: 1.0670 - accuracy: 0.9250 - val_loss: 1.4973 - val_accuracy: 0.9335\n",
      "Epoch 4/10\n",
      "354/354 [==============================] - 12s 35ms/step - loss: 5.7875 - accuracy: 0.8975 - val_loss: 6.7188 - val_accuracy: 0.9316\n",
      "Epoch 5/10\n",
      "354/354 [==============================] - 12s 35ms/step - loss: 31.8966 - accuracy: 0.8734 - val_loss: 16.1506 - val_accuracy: 0.8741\n",
      "Epoch 6/10\n",
      "354/354 [==============================] - 12s 35ms/step - loss: 308.8495 - accuracy: 0.7129 - val_loss: 29.9282 - val_accuracy: 0.8301\n",
      "Epoch 7/10\n",
      "354/354 [==============================] - 12s 35ms/step - loss: 38.4793 - accuracy: 0.7992 - val_loss: 28.1875 - val_accuracy: 0.8314\n",
      "Epoch 8/10\n",
      "354/354 [==============================] - 12s 35ms/step - loss: 39.0772 - accuracy: 0.8069 - val_loss: 23.1183 - val_accuracy: 0.8598\n",
      "Epoch 9/10\n",
      "354/354 [==============================] - 12s 35ms/step - loss: 34.0330 - accuracy: 0.8181 - val_loss: 27.2941 - val_accuracy: 0.8521\n",
      "Epoch 10/10\n",
      "354/354 [==============================] - 12s 35ms/step - loss: 32.8951 - accuracy: 0.8226 - val_loss: 27.9040 - val_accuracy: 0.8320\n",
      "118/118 [==============================] - 2s 13ms/step - loss: 26.3022 - accuracy: 0.8330\n",
      "Test Accuracy: 0.8330241441726685\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Example for the medium complexity model\n",
    "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, batch_size=32)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f'Test Accuracy: {test_acc}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-metal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
