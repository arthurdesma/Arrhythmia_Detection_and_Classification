{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fusionné = pd.read_csv('df_fusionné.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fusionné = df_fusionné.sample(frac=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anormal = df_fusionné[df_fusionné[\"ColumnName\"] != \"N\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ColumnName\n",
      "Q    8043\n",
      "V    7236\n",
      "S    2781\n",
      "F     803\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "value_counts = df_anormal[\"ColumnName\"].value_counts()\n",
    "print(value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_anormal.iloc[:, 1:]\n",
    "y = df_anormal.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "y_categorical = to_categorical(y_encoded)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_categorical, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2160"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_15 (Conv1D)          (None, 2155, 64)          448       \n",
      "                                                                 \n",
      " max_pooling1d_15 (MaxPooli  (None, 718, 64)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " batch_normalization_15 (Ba  (None, 718, 64)           256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv1d_16 (Conv1D)          (None, 713, 128)          49280     \n",
      "                                                                 \n",
      " max_pooling1d_16 (MaxPooli  (None, 356, 128)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " batch_normalization_16 (Ba  (None, 356, 128)          512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv1d_17 (Conv1D)          (None, 351, 128)          98432     \n",
      "                                                                 \n",
      " max_pooling1d_17 (MaxPooli  (None, 175, 128)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " batch_normalization_17 (Ba  (None, 175, 128)          512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv1d_18 (Conv1D)          (None, 170, 64)           49216     \n",
      "                                                                 \n",
      " max_pooling1d_18 (MaxPooli  (None, 85, 64)            0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " batch_normalization_18 (Ba  (None, 85, 64)            256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 5440)              0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 64)                348224    \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 4)                 132       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 549348 (2.10 MB)\n",
      "Trainable params: 548580 (2.09 MB)\n",
      "Non-trainable params: 768 (3.00 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Conv1D(filters=64, kernel_size=6, activation='relu', input_shape=(X_train.shape[1], 1)),\n",
    "    MaxPooling1D(pool_size=3),\n",
    "    BatchNormalization(),\n",
    "\n",
    "    Conv1D(filters=128, kernel_size=6, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    BatchNormalization(),\n",
    "\n",
    "    Conv1D(filters=128, kernel_size=6, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    BatchNormalization(),\n",
    "\n",
    "    Conv1D(filters=64, kernel_size=6, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    BatchNormalization(),\n",
    "\n",
    "    Flatten(),\n",
    "\n",
    "    Dense(64, activation='relu'),\n",
    "\n",
    "    Dense(32, activation='relu'),\n",
    "\n",
    "    Dense(4, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "354/354 [==============================] - 14s 36ms/step - loss: 0.4498 - accuracy: 0.9100 - val_loss: 0.7126 - val_accuracy: 0.8031\n",
      "Epoch 2/10\n",
      "354/354 [==============================] - 12s 34ms/step - loss: 0.3175 - accuracy: 0.9443 - val_loss: 0.2777 - val_accuracy: 0.9465\n",
      "Epoch 3/10\n",
      "354/354 [==============================] - 12s 34ms/step - loss: 1.0670 - accuracy: 0.9250 - val_loss: 1.4973 - val_accuracy: 0.9335\n",
      "Epoch 4/10\n",
      "354/354 [==============================] - 12s 35ms/step - loss: 5.7875 - accuracy: 0.8975 - val_loss: 6.7188 - val_accuracy: 0.9316\n",
      "Epoch 5/10\n",
      "354/354 [==============================] - 12s 35ms/step - loss: 31.8966 - accuracy: 0.8734 - val_loss: 16.1506 - val_accuracy: 0.8741\n",
      "Epoch 6/10\n",
      "354/354 [==============================] - 12s 35ms/step - loss: 308.8495 - accuracy: 0.7129 - val_loss: 29.9282 - val_accuracy: 0.8301\n",
      "Epoch 7/10\n",
      "354/354 [==============================] - 12s 35ms/step - loss: 38.4793 - accuracy: 0.7992 - val_loss: 28.1875 - val_accuracy: 0.8314\n",
      "Epoch 8/10\n",
      "354/354 [==============================] - 12s 35ms/step - loss: 39.0772 - accuracy: 0.8069 - val_loss: 23.1183 - val_accuracy: 0.8598\n",
      "Epoch 9/10\n",
      "354/354 [==============================] - 12s 35ms/step - loss: 34.0330 - accuracy: 0.8181 - val_loss: 27.2941 - val_accuracy: 0.8521\n",
      "Epoch 10/10\n",
      "354/354 [==============================] - 12s 35ms/step - loss: 32.8951 - accuracy: 0.8226 - val_loss: 27.9040 - val_accuracy: 0.8320\n",
      "118/118 [==============================] - 2s 13ms/step - loss: 26.3022 - accuracy: 0.8330\n",
      "Test Accuracy: 0.8330241441726685\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Example for the medium complexity model\n",
    "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, batch_size=32)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f'Test Accuracy: {test_acc}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-metal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
